{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b255a26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\phobert_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    \n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "from underthesea import sent_tokenize\n",
    "\n",
    "from rag_model.model.RE.final_re import *\n",
    "from rag_model.model.NER.final_ner import *\n",
    "from shared_functions.gg_sheet_drive import *\n",
    "from shared_functions.global_functions import *\n",
    "from rag_model.model.Final_pipeline.final_relation_extractor import *\n",
    "from rag_model.model.Final_pipeline.final_doc_processor import *\n",
    "\n",
    "with open('D:/Study/Education/Projects/Group_Project/rag_model/model/RE/artifact/id2relation.json', 'r') as f:\n",
    "    id2relation = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bf9e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vncorenlp import VnCoreNLP\n",
    "\n",
    "ner_annotator = None\n",
    "# ner_annotator = VnCoreNLP(\"D:/Study/Education/Projects/Group_Project/VnCoreNLP/VnCoreNLP-1.1.1.jar\", annotators=\"wseg,pos,ner\", max_heap_size='-Xmx2g') \n",
    "\n",
    "ner = NER(\n",
    "    model_path=\"D:/Study/Education/Projects/Group_Project/rag_model/model/NER/artifact/model_bilstm_crf.pt\",\n",
    "    token2idx_path=\"D:/Study/Education/Projects/Group_Project/rag_model/model/NER/artifact/token2idx.json\",\n",
    "    label2idx_path=\"D:/Study/Education/Projects/Group_Project/rag_model/model/NER/artifact/label2idx.json\",\n",
    "    annotator = ner_annotator\n",
    ")\n",
    "\n",
    "re_model = RE(checkpoint = 'D:/Study/Education/Projects/Group_Project/rag_model/model/RE/artifact/re_8_train_phobert_1_3.pth',\n",
    "           use_phobert=True, id2relation=id2relation, encoder_layer=1, decoder_layer=3, use_rel_pos=False, freeze_train=True) #match the model configuration\n",
    "\n",
    "final_re = Extractor(ner, re_model)\n",
    "\n",
    "processor = Doc_processor(ner, re_model, final_re)\n",
    "\n",
    "phobert = PhoBertEmbedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5ee4e2",
   "metadata": {},
   "source": [
    "### Support function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9676eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mask = ['luáº­t', 'thÃ´ng', 'nghá»‹', 'hiáº¿n', 'quyáº¿t', 'Ä‘á»‹nh', 'phÃ¡p', 'tÆ°', 'Ä‘iá»u', 'má»¥c', 'pháº§n', 'khoáº£n', 'Ä‘iá»ƒm']\n",
    "\n",
    "def final_relation_check(text, df):\n",
    "    re_result = re_model.predict(text)\n",
    "    ner_result = ner.extract_document_metadata(text)\n",
    "\n",
    "    # Safety checks\n",
    "    if re_result is None or 'Span' not in re_result.columns or re_result['Span'].isna().all():\n",
    "        return df\n",
    "\n",
    "    # Get a clean span string\n",
    "    span = str(re_result['Span'].iloc[0]).lower()\n",
    "    span_tokens = re.findall(r'\\w+', span)\n",
    "\n",
    "    # Rule check\n",
    "    if any(token in check_mask for token in span_tokens):\n",
    "        meta = ner_result[['issue_date', 'title', 'document_id', 'document_type']].iloc[:1].reset_index(drop=True)\n",
    "        rel = re_result.iloc[:1].reset_index(drop=True)\n",
    "        combined = pd.concat([rel, meta], axis=1)\n",
    "        df = pd.concat([df, combined], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25273133",
   "metadata": {},
   "source": [
    "#### extract_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5151104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences(text):\n",
    "    sentences = []\n",
    "    buffer = \"\"\n",
    "\n",
    "    for line in text.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        if buffer:\n",
    "            buffer += \" \" + line\n",
    "        else:\n",
    "            buffer = line\n",
    "\n",
    "        # If the current line ends with ';', sentence is complete\n",
    "        if line.endswith(';'):\n",
    "            sentences.append(buffer.strip())\n",
    "            buffer = \"\"\n",
    "\n",
    "    # Append leftover if it doesnâ€™t end with ;\n",
    "    if buffer:\n",
    "        sentences.append(buffer.strip())\n",
    "\n",
    "    # Drop everything before the first \"CÄƒn cá»©\"\n",
    "    for i, s in enumerate(sentences):\n",
    "        if \"CÄƒn cá»©\" in s:\n",
    "            idx = s.find(\"CÄƒn cá»©\")\n",
    "            sentences[i] = s[idx:].strip()\n",
    "            sentences = sentences[i:]\n",
    "            break\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a595d764",
   "metadata": {},
   "source": [
    "#### Final relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa45aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_relation(text):\n",
    "    check_mask = ['luáº­t', 'thÃ´ng', 'nghá»‹', 'hiáº¿n', 'quyáº¿t', 'Ä‘á»‹nh', 'phÃ¡p', 'tÆ°', 'Ä‘iá»u', 'má»¥c', 'pháº§n', 'khoáº£n', 'Ä‘iá»ƒm']\n",
    "\n",
    "    # Take only the first sentence\n",
    "    first_sent = sent_tokenize(text)[0]\n",
    "    sents = extract_sentences(first_sent)\n",
    "\n",
    "    df = pd.DataFrame(columns=['Text', 'Self Root', 'Relation', 'Span', 'issue_date', 'title', 'document_id', 'document_type'])\n",
    "\n",
    "    # Proper filtering loop\n",
    "    for sent in sents:\n",
    "        df_meta = ner.extract_document_metadata(sent)\n",
    "            # check if any keyword in check_mask appears in the sentence\n",
    "        if (any(token in sent.lower() for token in check_mask)) and ((len(df_meta['document_id'].iloc[0]) > 0) or ('nÃ y' in sent.split())):\n",
    "            df = final_relation_check(sent, df)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a48063",
   "metadata": {},
   "source": [
    "#### Try ID extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f6bc0e",
   "metadata": {},
   "source": [
    "#### parse legal ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dfad0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def to_roman(num):\n",
    "    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n",
    "    syms = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n",
    "    roman = \"\"\n",
    "    i = 0\n",
    "    while num > 0:\n",
    "        for _ in range(num // val[i]):\n",
    "            roman += syms[i]\n",
    "            num -= val[i]\n",
    "        i += 1\n",
    "    return roman\n",
    "\n",
    "def parse_legal_ref(text, root=None):\n",
    "    text = unicodedata.normalize(\"NFC\", text)\n",
    "    lower_text = text.lower()\n",
    "\n",
    "    # Order from high â†’ low\n",
    "    hierarchy = [\"doc\", \"chapter\", \"C\", \"P\", \"SP\", \"SSP\", \"SSSP\"]\n",
    "    \n",
    "    map_type = {\n",
    "        \"chapter\": \"Chapter\",\n",
    "        \"C\": \"Clause\",\n",
    "        \"P\": \"Point\",\n",
    "        \"SP\": \"Subpoint\",\n",
    "        \"SSP\": \"Subsubpoint\",\n",
    "        \"SSSP\": \"Subsubsubpoint\"\n",
    "    }\n",
    "\n",
    "    #-ğŸ 1) Parse existing root structure-\n",
    "    existing = {key: None for key in hierarchy}\n",
    "    lowest_level_index = -1\n",
    "\n",
    "    if root:\n",
    "        root = re.sub(r'(.*)_doc_\\1', r'\\1', root)\n",
    "        \n",
    "        parts = root.split(\"_\")\n",
    "        for p in parts:\n",
    "            if p.startswith(\"SSSP_\"):\n",
    "                existing[\"SSSP\"] = p[5:]\n",
    "            elif p.startswith(\"SSP_\"):\n",
    "                existing[\"SSP\"] = p[4:]\n",
    "            elif p.startswith(\"SP_\"):\n",
    "                existing[\"SP\"] = p[3:]\n",
    "            elif p.startswith(\"P_\"):\n",
    "                existing[\"P\"] = p[2:]\n",
    "            elif p.startswith(\"C_\"):\n",
    "                existing[\"C\"] = p[2:]\n",
    "            elif p.startswith(\"chapter_\"):\n",
    "                existing[\"chapter\"] = p.split(\"chapter_\")[1]\n",
    "            elif existing[\"doc\"] is None:  # First non-prefixed part = doc\n",
    "                existing[\"doc\"] = p\n",
    "\n",
    "        for i, k in enumerate(hierarchy):\n",
    "            if existing[k] is not None:\n",
    "                lowest_level_index = i\n",
    "\n",
    "    # 2) Parse new information from text\n",
    "    result = {k: None for k in hierarchy}\n",
    "    result[\"SP\"], result[\"SSP\"], result[\"SSSP\"] = [], [], []\n",
    "\n",
    "    # Document ID (only if no root)\n",
    "    if root is None:\n",
    "        m = re.search(r\"sá»‘\\s*([A-Za-z0-9/.\\-ÄÄ‘]+)\", text)\n",
    "        if m:\n",
    "            result[\"doc\"] = m.group(1).upper()\n",
    "\n",
    "    # Chapter\n",
    "    if m := re.search(r\"chÆ°Æ¡ng\\s*(\\d+)\", lower_text):\n",
    "        result[\"chapter\"] = to_roman(int(m.group(1)))\n",
    "\n",
    "    # Clause\n",
    "    if m := re.search(r\"Ä‘iá»u\\s*(\\d+)\", lower_text):\n",
    "        result[\"C\"] = m.group(1)\n",
    "\n",
    "    # Point\n",
    "    if m := re.search(r\"khoáº£n\\s*(\\d+)\", lower_text):\n",
    "        result[\"P\"] = m.group(1)\n",
    "\n",
    "    # Subpoints and deeper levels\n",
    "    for match in re.findall(r\"Ä‘iá»ƒm\\s*([a-z](?:\\.\\d+)*)\", lower_text):\n",
    "        depth = match.count(\".\") + 1\n",
    "        key = {1: \"SP\", 2: \"SSP\", 3: \"SSSP\"}.get(depth, \"SP\")\n",
    "        result[key].append(match)\n",
    "\n",
    "    # 3) Build final structure safely\n",
    "    final = []\n",
    "\n",
    "    if root:\n",
    "        parts = root.split(\"_\")\n",
    "        final = parts[1:] if parts[0] == \"doc\" else parts  \n",
    "    # else:\n",
    "    #     # if result[\"doc\"]:\n",
    "    #     #     final.append(result[\"doc\"])\n",
    "    #     if result[\"chapter\"]:\n",
    "    #         final.append(f\"chapter_{result['chapter']}\")\n",
    "    #     if result[\"C\"]:\n",
    "    #         final.append(f\"C_{result['C']}\")\n",
    "\n",
    "    # Append deeper levels than existing\n",
    "    for i, level in enumerate(hierarchy):\n",
    "        if i <= lowest_level_index:\n",
    "            continue  # Keep hierarchy stable\n",
    "\n",
    "        val = result[level]\n",
    "        if val:\n",
    "            if level in [\"SP\", \"SSP\", \"SSSP\"]:\n",
    "                for v in val:\n",
    "                    final.append(f\"{level}_{v}\")\n",
    "            else:\n",
    "                final.append(f\"{level}_{val}\" if i > 0 else f\"{val}\")\n",
    "\n",
    "    #4) Determine node type-\n",
    "    last = final[-1]\n",
    "    prefix = last.split(\"_\")[0]\n",
    "    node_type = map_type.get(prefix, \"Document\")\n",
    "\n",
    "    return \"_\".join(final), node_type\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2dbf14",
   "metadata": {},
   "source": [
    "#### extract multiple entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1d589f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy_word = {\n",
    "    'chapter': re.compile(r'chÆ°Æ¡ng\\s*([ivxlcdm\\d]+)', re.IGNORECASE),\n",
    "    'clause':  re.compile(r'Ä‘iá»u\\s*(\\d+)', re.IGNORECASE),\n",
    "    'point':   re.compile(r'khoáº£n\\s*(\\d+)', re.IGNORECASE),\n",
    "    'subpoint':re.compile(r'Ä‘iá»ƒm\\s*([a-z])', re.IGNORECASE),\n",
    "    'subsubpoint':re.compile(r'Ä‘iá»ƒm\\s*([a-z]\\.\\d+)', re.IGNORECASE),\n",
    "    'subsubsubpoint':re.compile(r'Ä‘iá»ƒm\\s*([a-z]\\.\\d+\\.\\d+)', re.IGNORECASE)\n",
    "}\n",
    "\n",
    "mapping = {'chapter': 'chÆ°Æ¡ng', 'clause': 'Ä‘iá»u', 'point': 'khoáº£n', 'subpoint': 'Ä‘iá»ƒm', 'subsubpoint': 'Ä‘iá»ƒm', 'subsubsubpoint': 'Ä‘iá»ƒm'}\n",
    "\n",
    "splitting_char = re.compile(r'\\s*(,|\\bvÃ \\b|\\bhoáº·c\\b)\\s*', re.IGNORECASE)\n",
    "hierarchy_range = re.compile(r'(Ä‘iá»u|khoáº£n|Ä‘iá»ƒm|chÆ°Æ¡ng)\\s*(\\d+|[a-z])\\s*Ä‘áº¿n\\s*\\1\\s*(\\d+|[a-z])', re.IGNORECASE)\n",
    "number = re.compile(r'^\\d+$')\n",
    "word = re.compile(r'^[a-z]$')\n",
    "\n",
    "def expand_ranges(text):\n",
    "    # Handle ranges like \"Äiá»u 5 Ä‘áº¿n Äiá»u 10\" or \"khoáº£n a Ä‘áº¿n khoáº£n d\"\n",
    "    \n",
    "    def repl(m):\n",
    "        lvl, s, e = m.group(1).lower(), m.group(2), m.group(3) #capture same level hierarchy word and their values\n",
    "        if s.isdigit() and e.isdigit():\n",
    "            s, e = int(s), int(e)\n",
    "            return ', '.join(f'{lvl} {i}' for i in range(s, e + 1))\n",
    "        elif s.isalpha() and e.isalpha():\n",
    "            return ', '.join(f'{lvl} {chr(i)}' for i in range(ord(s), ord(e) + 1))\n",
    "        return m.group(0)\n",
    "    return hierarchy_range.sub(repl, text)\n",
    "\n",
    "def extract_entities(text): \n",
    "    '''\n",
    "    Extract multiple entities from a multi-entities sentence in a raw text format\n",
    "    '''\n",
    "    check = ['Ä‘iá»u', 'khoáº£n', 'Ä‘iá»ƒm']\n",
    "    \n",
    "    try_text = text.lower().split()\n",
    "    if not any(word in try_text for word in check):\n",
    "        return text\n",
    "\n",
    "    else:\n",
    "        text = text.lower().strip()\n",
    "        text = expand_ranges(text)\n",
    "        # Split with capture so we can detect separators directly\n",
    "        levels = ['chapter', 'clause', 'point', 'subpoint', 'subsubpoint', 'subsubsubpoint'] if 'chÆ°Æ¡ng' in text else ['clause', 'point', 'subpoint', 'subsubpoint', 'subsubsubpoint']\n",
    "\n",
    "        # Split with capture so we can detect separators directly\n",
    "        tokens = splitting_char.split(text)\n",
    "        segments = []\n",
    "        for i in range(0, len(tokens), 2):\n",
    "            seg = tokens[i].strip()\n",
    "            sep = tokens[i+1].strip() if i+1 < len(tokens) else None\n",
    "            segments.append((seg, sep))\n",
    "\n",
    "        results, last_levels = [], {lvl: None for lvl in levels}\n",
    "        last_anchor_level = None\n",
    "\n",
    "        for seg, sep in segments:\n",
    "            if not seg:\n",
    "                continue\n",
    "\n",
    "            # detect anchors\n",
    "            anchors_found = {}\n",
    "            for lvl in levels:\n",
    "                matches = hierarchy_word[lvl].findall(seg)\n",
    "                if matches:\n",
    "                    val = matches[-1]\n",
    "                    if lvl in ('clause', 'point'):\n",
    "                        try: val = int(val)\n",
    "                        except: pass\n",
    "                    anchors_found[lvl] = val\n",
    "\n",
    "            # If segment has anchor(s)\n",
    "            if anchors_found:\n",
    "                entity = deepcopy(last_levels)\n",
    "                for lvl in levels:\n",
    "                    if lvl in anchors_found:\n",
    "                        entity[lvl] = anchors_found[lvl]\n",
    "                        # clear lower levels\n",
    "                        for l in levels[levels.index(lvl)+1:]:\n",
    "                            entity[l] = None\n",
    "                results.append({k: v for k, v in entity.items() if v is not None})\n",
    "                last_anchor_level = next(iter(anchors_found))\n",
    "                for lvl in levels:\n",
    "                    if entity.get(lvl) is not None:\n",
    "                        last_levels[lvl] = entity[lvl]\n",
    "\n",
    "            else:\n",
    "                # bare number or letter segment\n",
    "                tokens2 = re.split(r'\\s+', seg)\n",
    "                for t in tokens2:\n",
    "                    if not t:\n",
    "                        continue\n",
    "                    if number.match(t):\n",
    "                        assign_level = last_anchor_level or levels[0]\n",
    "                        entity = deepcopy(last_levels)\n",
    "                        val = int(t)\n",
    "                        entity[assign_level] = val\n",
    "                        for l in levels[levels.index(assign_level)+1:]:\n",
    "                            entity[l] = None\n",
    "                        results.append({k: v for k, v in entity.items() if v is not None})\n",
    "                        last_levels[assign_level] = val\n",
    "                    elif word.match(t): #and last_anchor_level in ['subpoint', 'subsubpoint', 'subsubsubpoint']:\n",
    "                        assign_level = 'subpoint' if 'subpoint' in levels else levels[-1]\n",
    "                        entity = deepcopy(last_levels)\n",
    "                        entity[assign_level] = t\n",
    "                        results.append({k: v for k, v in entity.items() if v is not None})\n",
    "                        last_levels[assign_level] = t\n",
    "                        last_anchor_level = assign_level\n",
    "\n",
    "            # Reset context if highest-level entity ends with a splitting character\n",
    "            if sep and any(lvl in anchors_found for lvl in ('chapter', 'clause')):\n",
    "                for lvl in levels:\n",
    "                    last_levels[lvl] = None\n",
    "                last_anchor_level = None\n",
    "        \n",
    "        # Fix missing higher-level linkage (lookahead propagation)\n",
    "        final_results = []\n",
    "        for i, e in enumerate(results):\n",
    "            # if a sub-level exists without its parent\n",
    "            if 'subsubsubpoint' in e or 'subsubpoint' in e or 'subpoint' in e:\n",
    "                if 'point' not in e or 'clause' not in e:\n",
    "                    for j in range(i + 1, len(results)):\n",
    "                        future = results[j]\n",
    "                        if 'point' in future and 'point' not in e:\n",
    "                            e['point'] = future['point']\n",
    "                        if 'clause' in future and 'clause' not in e:\n",
    "                            e['clause'] = future['clause']\n",
    "                        # stop once weâ€™ve filled both\n",
    "                        if 'clause' in e and 'point' in e:\n",
    "                            break\n",
    "\n",
    "            # if a point exists but no clause, link to next clause\n",
    "            elif 'point' in e and 'clause' not in e:\n",
    "                for j in range(i + 1, len(results)):\n",
    "                    future = results[j]\n",
    "                    if 'clause' in future:\n",
    "                        e['clause'] = future['clause']\n",
    "                        break\n",
    "\n",
    "            final_results.append(e)\n",
    "\n",
    "        map_list = []    \n",
    "        \n",
    "        df_meta = ner.extract_document_metadata(text)\n",
    "        doc_id = df_meta['document_id'].iloc[0] if df_meta['document_id'] is not None else None\n",
    "        \n",
    "        for pair in final_results:\n",
    "            result = ''\n",
    "            for key, value in pair.items():\n",
    "                if key in mapping:\n",
    "                    temp = f'{mapping[key]} {str(value)}'\n",
    "                    \n",
    "                result += f'{temp} '\n",
    "                \n",
    "            result += f'vÄƒn báº£n sá»‘ {doc_id}' if doc_id else ''\n",
    "                    \n",
    "            map_list.append(result.strip())\n",
    "            \n",
    "        return map_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580973c",
   "metadata": {},
   "source": [
    "#### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c60f2b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relation_entities(text, root = None): # Root works as root ID for \"nÃ y\" cases\n",
    "    '''\n",
    "    Return the self-root, relation type and list of second entity IDs\n",
    "    root: input root node id for \"nÃ y\" cases to be filled\n",
    "    '''\n",
    "    text = text.lower().strip()\n",
    "    df_relation = final_relation(text)\n",
    "    self_root = df_relation['Self Root'].iloc[0] if not df_relation.empty else None\n",
    "    relation = df_relation['Relation'].iloc[0] if not df_relation.empty else None\n",
    "    info = ner.extract_document_metadata(text)\n",
    "    \n",
    "    if len(df_relation) > 0:\n",
    "        if info['document_id'] is not None:\n",
    "            span = df_relation['Span'].iloc[0] if not df_relation.empty else None\n",
    "            entities = extract_entities(text)\n",
    "            mapped_entities = []\n",
    "            if len(entities) > 0:\n",
    "                for ent in entities:\n",
    "                    parsed_ref, ref_type = parse_legal_ref(ent, root)\n",
    "                    mapped_entities.append({parsed_ref:ref_type})\n",
    "            else: \n",
    "                mapped_entities.append({root:''})\n",
    "\n",
    "            return self_root, relation, mapped_entities\n",
    "        return None, None, None\n",
    "    \n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0526b34",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c75d1308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = ' Äiá»u 32, 33, 34, 51, 138 vÃ  139, Ä‘iá»ƒm b.1.1) khoáº£n 1 Äiá»u 163, khoáº£n 3 vÃ  khoáº£n 4 Äiá»u 179 cá»§a Luáº­t thi hÃ nh Ã¡n dÃ¢n sá»± sá»‘ 26/2008/QH12'\n",
    "\n",
    "# text = 'Äiá»u 63 vÃ  khoáº£n 2 Äiá»u 81 cá»§a Luáº­t Äáº¥t Ä‘ai Ä‘Æ°á»£c thay báº±ng cá»¥m tá»« â€œ dá»± Ã¡n Ä‘áº§u tÆ° â€'\n",
    "\n",
    "# text = 'Äiá»u 67 Ä‘áº¿n Äiá»u 78 vÃ  Äiá»u 105 cá»§a Luáº­t HÃ´n nhÃ¢n vÃ  gia Ä‘Ã¬nh sá»‘ 22/2000/QH10'\n",
    "\n",
    "# text = 'khoáº£n 2 Äiá»u 27, khoáº£n 3 Äiá»u 29, Äiá»u 31, khoáº£n 3 Äiá»u 32 vÃ  Äiá»u 85 cá»§a Luáº­t ban hÃ nh vÄƒn báº£n quy pháº¡m phÃ¡p luáº­t'\n",
    "\n",
    "text = 'Ä‘iá»ƒm a Ä‘áº¿n Ä‘iá»ƒm e Ä‘iá»u 32 hoáº·c Ä‘iá»u 35, Ä‘iá»ƒm b.1.1), Ä‘iá»ƒm c.1), Ä‘iá»ƒm d.1) hoáº·c Ä‘iá»ƒm e.2) khoáº£n 2 Ä‘iá»u 1, khoáº£n 3 Ä‘iá»u 10 luáº­t sá»‘ 20/2019/QH14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7200561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ä‘iá»ƒm a Ä‘iá»u 32 khoáº£n 2 vÄƒn báº£n sá»‘ 20/2019/QH14 ('20/2019/QH14_C_32_P_2_SP_a', 'Subpoint')\n",
      "Ä‘iá»ƒm b Ä‘iá»u 32 khoáº£n 2 vÄƒn báº£n sá»‘ 20/2019/QH14 ('20/2019/QH14_C_32_P_2_SP_b', 'Subpoint')\n",
      "Ä‘iá»ƒm c Ä‘iá»u 32 khoáº£n 2 vÄƒn báº£n sá»‘ 20/2019/QH14 ('20/2019/QH14_C_32_P_2_SP_c', 'Subpoint')\n",
      "Ä‘iá»ƒm d Ä‘iá»u 32 khoáº£n 2 vÄƒn báº£n sá»‘ 20/2019/QH14 ('20/2019/QH14_C_32_P_2_SP_d', 'Subpoint')\n",
      "Ä‘iá»u 32 Ä‘iá»ƒm e khoáº£n 2 vÄƒn báº£n sá»‘ 20/2019/QH14 ('20/2019/QH14_C_32_P_2_SP_e', 'Subpoint')\n",
      "Ä‘iá»u 35 vÄƒn báº£n sá»‘ 20/2019/QH14 ('20/2019/QH14_C_35', 'Clause')\n",
      "Ä‘iá»ƒm b Ä‘iá»ƒm b.1 Ä‘iá»ƒm b.1.1 khoáº£n 2 Ä‘iá»u 1 vÄƒn báº£n sá»‘ 20/2019/QH14 ('20/2019/QH14_C_1_P_2_SP_b_SSP_b.1_SSSP_b.1.1', 'Subsubsubpoint')\n",
      "Ä‘iá»ƒm c Ä‘iá»ƒm c.1 khoáº£n 2 Ä‘iá»u 1 vÄƒn báº£n sá»‘ 20/2019/QH14 ('20/2019/QH14_C_1_P_2_SP_c_SSP_c.1', 'Subsubpoint')\n",
      "Ä‘iá»ƒm d Ä‘iá»ƒm d.1 khoáº£n 2 Ä‘iá»u 1 vÄƒn báº£n sá»‘ 20/2019/QH14 ('20/2019/QH14_C_1_P_2_SP_d_SSP_d.1', 'Subsubpoint')\n",
      "Ä‘iá»u 1 khoáº£n 2 Ä‘iá»ƒm e Ä‘iá»ƒm e.2 vÄƒn báº£n sá»‘ 20/2019/QH14 ('20/2019/QH14_C_1_P_2_SP_e_SSP_e.2', 'Subsubpoint')\n",
      "Ä‘iá»u 10 khoáº£n 3 vÄƒn báº£n sá»‘ 20/2019/QH14 ('20/2019/QH14_C_10_P_3', 'Point')\n"
     ]
    }
   ],
   "source": [
    "list_ent = extract_entities(text)\n",
    "for ent in list_ent:\n",
    "    print(ent, parse_legal_ref(ent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14437959",
   "metadata": {},
   "source": [
    "#### parse_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99067db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_unicode(s: str) -> str:\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    s = s.replace(\"\\u00A0\", \" \").replace(\"\\u202F\", \" \").replace(\"\\u200B\", \"\")\n",
    "    return s.strip()\n",
    "\n",
    "def parse_legal_text(text: str):\n",
    "    # Normalize each line and rebuild\n",
    "    clean_lines = [normalize_unicode(line) for line in text.splitlines()]\n",
    "    clean_text = \"\\n\".join(clean_lines)\n",
    "\n",
    "    chapter_pattern = r\"(?i)^\\s*chÆ°Æ¡ng\\s+([IVXLCDM\\d]+)\\b\"\n",
    "    clause_pattern = r\"^\\s*Äiá»u\\s+(\\d+)\\b\"\n",
    "    point_pattern = r\"^\\s*(\\d+)\\.\"\n",
    "    subpoint_pattern = r\"^\\s*([a-z])\\)\"\n",
    "    subsubpoint_pattern = r\"^\\s*([a-z])\\.(\\d+)\\)\"\n",
    "    subsubsubpoint_pattern = r\"^\\s*([a-z])\\.(\\d+)\\.(\\d+)\\)\"\n",
    "\n",
    "    # Detect if document has chapters\n",
    "    has_chapter = any(re.match(chapter_pattern, line) for line in clean_lines)\n",
    "\n",
    "    structure = OrderedDict()\n",
    "    if has_chapter:\n",
    "        structure[\"chapters\"] = OrderedDict()\n",
    "    else:\n",
    "        structure[\"clauses\"] = []\n",
    "\n",
    "    current_chapter = None\n",
    "    current_clause = None\n",
    "    current_point = None\n",
    "    current_subpoint = None\n",
    "    current_subsubpoint = None\n",
    "    current_subsubsubpoint = None\n",
    "\n",
    "    for line in clean_lines:\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Chapter\n",
    "        mch = re.match(chapter_pattern, line)\n",
    "        if mch and has_chapter:\n",
    "            chap_key = f\"chapter {mch.group(1)}\"\n",
    "            structure[\"chapters\"][chap_key] = {\n",
    "                \"title\": line,\n",
    "                \"text\": \"\",\n",
    "                \"clauses\": []\n",
    "            }\n",
    "            current_chapter = chap_key\n",
    "            current_clause = current_point = current_subpoint = current_subsubpoint = current_subsubsubpoint = None\n",
    "            continue\n",
    "\n",
    "        # Clause (Äiá»u)\n",
    "        mcl = re.match(clause_pattern, line)\n",
    "        if mcl:\n",
    "            clause_entry = {\"clause\": mcl.group(1), \"text\": line, \"points\": []}\n",
    "            if has_chapter:\n",
    "                if current_chapter is None:\n",
    "                    current_chapter = \"no_chapter\"\n",
    "                    structure[\"chapters\"].setdefault(current_chapter, {\"title\": \"\", \"text\": \"\", \"clauses\": []})\n",
    "                structure[\"chapters\"][current_chapter][\"clauses\"].append(clause_entry)\n",
    "            else:\n",
    "                structure[\"clauses\"].append(clause_entry)\n",
    "            current_clause = clause_entry\n",
    "            current_point = current_subpoint = current_subsubpoint = current_subsubsubpoint = None\n",
    "            continue\n",
    "\n",
    "        # Point (1.)\n",
    "        mp = re.match(point_pattern, line)\n",
    "        if mp and current_clause is not None:\n",
    "            current_point = {\"point\": mp.group(1), \"text\": line, \"subpoints\": []}\n",
    "            current_clause[\"points\"].append(current_point)\n",
    "            current_subpoint = current_subsubpoint = current_subsubsubpoint = None\n",
    "            continue\n",
    "\n",
    "        # Subpoint (a))\n",
    "        ms = re.match(subpoint_pattern, line)\n",
    "        if ms and current_point is not None:\n",
    "            current_subpoint = {\"subpoint\": ms.group(1), \"text\": line, \"subsubpoints\": []}\n",
    "            current_point[\"subpoints\"].append(current_subpoint)\n",
    "            current_subsubpoint = current_subsubsubpoint = None\n",
    "            continue\n",
    "\n",
    "        # SubSubpoint (a.1))\n",
    "        mss = re.match(subsubpoint_pattern, line)\n",
    "        if mss and current_subpoint is not None:\n",
    "            tag = f\"{mss.group(1)}.{mss.group(2)}\"\n",
    "            current_subsubpoint = {\"subsubpoint\": tag, \"text\": line, \"subsubsubpoints\": []}\n",
    "            current_subpoint[\"subsubpoints\"].append(current_subsubpoint)\n",
    "            current_subsubsubpoint = None\n",
    "            continue\n",
    "\n",
    "        # SubSubSubpoint (a.1.1))\n",
    "        msss = re.match(subsubsubpoint_pattern, line)\n",
    "        if msss and current_subsubpoint is not None:\n",
    "            tag = f\"{msss.group(1)}.{msss.group(2)}.{msss.group(3)}\"\n",
    "            current_subsubsubpoint = {\"subsubsubpoint\": tag, \"text\": line}\n",
    "            current_subsubpoint[\"subsubsubpoints\"].append(current_subsubsubpoint)\n",
    "            continue\n",
    "\n",
    "        # Continuation of content\n",
    "        if current_subsubsubpoint is not None:\n",
    "            current_subsubsubpoint[\"text\"] += \"\\n\" + line\n",
    "        elif current_subsubpoint is not None:\n",
    "            current_subsubpoint[\"text\"] += \"\\n\" + line\n",
    "        elif current_subpoint is not None:\n",
    "            current_subpoint[\"text\"] += \"\\n\" + line\n",
    "        elif current_point is not None:\n",
    "            current_point[\"text\"] += \"\\n\" + line\n",
    "        elif current_clause is not None:\n",
    "            current_clause[\"text\"] += \"\\n\" + line\n",
    "        elif has_chapter and current_chapter is not None:\n",
    "            prev = structure[\"chapters\"][current_chapter][\"text\"]\n",
    "            structure[\"chapters\"][current_chapter][\"text\"] = (prev + \"\\n\" + line) if prev else line\n",
    "\n",
    "    return structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae884e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'clauses': [{'clause': '1', 'text': 'Äiá»u 1. Sá»­a Ä‘á»•i, bá»• sung Luáº­t Doanh nghiá»‡p', 'points': [{'point': '1', 'text': '1. Sá»­a Ä‘á»•i, bá»• sung má»™t sá»‘ khoáº£n cá»§a Äiá»u 4 nhÆ° sau:', 'subpoints': [{'subpoint': 'a', 'text': 'a) Sá»­a Ä‘á»•i, bá»• sung khoáº£n 5 nhÆ° sau:\\nâ€œ5. Cá»• tá»©c lÃ  khoáº£n lá»£i nhuáº­n sau thuáº¿ Ä‘Æ°á»£c tráº£ cho má»—i cá»• pháº§n báº±ng tiá»n hoáº·c báº±ng tÃ i sáº£n\\nkhÃ¡c.â€;', 'subsubpoints': []}, {'subpoint': 'b', 'text': 'b) Sá»­a Ä‘á»•i, bá»• sung khoáº£n 14 nhÆ° sau:\\nâ€œ14. GiÃ¡ thá»‹ trÆ°á»ng cá»§a pháº§n vá»‘n gÃ³p hoáº·c cá»• pháº§n lÃ :', 'subsubpoints': []}, {'subpoint': 'a', 'text': 'a) GiÃ¡ giao dá»‹ch bÃ¬nh quÃ¢n trong vÃ²ng 30 ngÃ y liá»n ká» trÆ°á»›c ngÃ y xÃ¡c Ä‘á»‹nh giÃ¡ hoáº·c giÃ¡ thá»a\\nthuáº­n giá»¯a ngÆ°á»i bÃ¡n vÃ  ngÆ°á»i mua hoáº·c giÃ¡ do má»™t tá»• chá»©c tháº©m Ä‘á»‹nh giÃ¡ xÃ¡c Ä‘á»‹nh Ä‘á»‘i vá»›i cá»•\\nphiáº¿u niÃªm yáº¿t, Ä‘Äƒng kÃ½ giao dá»‹ch trÃªn há»‡ thá»‘ng giao dá»‹ch chá»©ng khoÃ¡n;', 'subsubpoints': []}, {'subpoint': 'b', 'text': 'b) GiÃ¡ giao dá»‹ch trÃªn thá»‹ trÆ°á»ng táº¡i thá»i Ä‘iá»ƒm liá»n ká» trÆ°á»›c Ä‘Ã³ hoáº·c giÃ¡ thá»a thuáº­n giá»¯a ngÆ°á»i bÃ¡n\\nvÃ  ngÆ°á»i mua hoáº·c giÃ¡ do má»™t tá»• chá»©c tháº©m Ä‘á»‹nh giÃ¡ xÃ¡c Ä‘á»‹nh Ä‘á»‘i vá»›i pháº§n vá»‘n gÃ³p hoáº·c cá»•\\npháº§n khÃ´ng thuá»™c Ä‘iá»ƒm a khoáº£n nÃ y.â€;', 'subsubpoints': []}, {'subpoint': 'c', 'text': 'c) Sá»­a Ä‘á»•i, bá»• sung khoáº£n 16 nhÆ° sau:\\nâ€œ16. Giáº¥y tá» phÃ¡p lÃ½ cá»§a cÃ¡ nhÃ¢n lÃ  má»™t trong cÃ¡c loáº¡i giáº¥y tá» sau Ä‘Ã¢y: tháº» CÄƒn cÆ°á»›c, tháº» CÄƒn\\ncÆ°á»›c cÃ´ng dÃ¢n, Há»™ chiáº¿u, giáº¥y tá» chá»©ng thá»±c cÃ¡ nhÃ¢n há»£p phÃ¡p khÃ¡c.â€;', 'subsubpoints': []}, {'subpoint': 'd', 'text': 'd) Bá»• sung khoáº£n 35 vÃ o sau khoáº£n 34 nhÆ° sau:\\nâ€œ35. Chá»§ sá»Ÿ há»¯u hÆ°á»Ÿng lá»£i cá»§a doanh nghiá»‡p cÃ³ tÆ° cÃ¡ch phÃ¡p nhÃ¢n (sau Ä‘Ã¢y gá»i lÃ  chá»§ sá»Ÿ há»¯u\\nhÆ°á»Ÿng lá»£i cá»§a doanh nghiá»‡p) lÃ  cÃ¡ nhÃ¢n cÃ³ quyá»n sá»Ÿ há»¯u trÃªn thá»±c táº¿ vá»‘n Ä‘iá»u lá»‡ hoáº·c cÃ³ quyá»n\\nchi phá»‘i Ä‘á»‘i vá»›i doanh nghiá»‡p Ä‘Ã³, trá»« trÆ°á»ng há»£p ngÆ°á»i Ä‘áº¡i diá»‡n chá»§ sá»Ÿ há»¯u trá»±c tiáº¿p táº¡i doanh\\nnghiá»‡p do NhÃ  nÆ°á»›c náº¯m giá»¯ 100% vá»‘n Ä‘iá»u lá»‡ vÃ  ngÆ°á»i Ä‘áº¡i diá»‡n pháº§n vá»‘n nhÃ  nÆ°á»›c táº¡i cÃ´ng ty\\ncá»• pháº§n, cÃ´ng ty trÃ¡ch nhiá»‡m há»¯u háº¡n hai thÃ nh viÃªn trá»Ÿ lÃªn theo quy Ä‘á»‹nh cá»§a phÃ¡p luáº­t vá» quáº£n\\nlÃ½ vÃ  Ä‘áº§u tÆ° vá»‘n nhÃ  nÆ°á»›c táº¡i doanh nghiá»‡p.â€.', 'subsubpoints': []}]}, {'point': '2', 'text': '2. Bá»• sung khoáº£n 5a vÃ o sau khoáº£n 5 Äiá»u 8 nhÆ° sau:\\nâ€œ5a. Thu tháº­p, cáº­p nháº­t, lÆ°u giá»¯ thÃ´ng tin vá» chá»§ sá»Ÿ há»¯u hÆ°á»Ÿng lá»£i cá»§a doanh nghiá»‡p; cung cáº¥p\\nthÃ´ng tin cho cÆ¡ quan nhÃ  nÆ°á»›c cÃ³ tháº©m quyá»n Ä‘á»ƒ xÃ¡c Ä‘á»‹nh chá»§ sá»Ÿ há»¯u hÆ°á»Ÿng lá»£i cá»§a doanh\\nnghiá»‡p khi Ä‘Æ°á»£c yÃªu cáº§u.â€.', 'subpoints': []}, {'point': '3', 'text': '3. Bá»• sung Ä‘iá»ƒm h vÃ o sau Ä‘iá»ƒm g khoáº£n 1 Äiá»u 11 nhÆ° sau:\\nâ€œh) Danh sÃ¡ch chá»§ sá»Ÿ há»¯u hÆ°á»Ÿng lá»£i cá»§a doanh nghiá»‡p (náº¿u cÃ³).â€.', 'subpoints': []}, {'point': '4', 'text': '4. Sá»­a Ä‘á»•i, bá»• sung khoáº£n 2 Äiá»u 13 nhÆ° sau:\\nâ€œ2. NgÆ°á»i Ä‘áº¡i diá»‡n theo phÃ¡p luáº­t cá»§a doanh nghiá»‡p chá»‹u trÃ¡ch nhiá»‡m cÃ¡ nhÃ¢n theo quy Ä‘á»‹nh cá»§a\\nphÃ¡p luáº­t Ä‘á»‘i vá»›i thiá»‡t háº¡i cho doanh nghiá»‡p do vi pháº¡m trÃ¡ch nhiá»‡m quy Ä‘á»‹nh táº¡i khoáº£n 1 Äiá»u\\nnÃ y.â€.', 'subpoints': []}, {'point': '5', 'text': '5. Sá»­a Ä‘á»•i, bá»• sung khoáº£n 4 vÃ  khoáº£n 5 Äiá»u 16 nhÆ° sau:\\nâ€œ4. KÃª khai giáº£ máº¡o, kÃª khai khÃ´ng trung thá»±c, kÃª khai khÃ´ng chÃ­nh xÃ¡c ná»™i dung há»“ sÆ¡ Ä‘Äƒng kÃ½\\ndoanh nghiá»‡p vÃ  ná»™i dung há»“ sÆ¡ Ä‘Äƒng kÃ½ thay Ä‘á»•i ná»™i dung Ä‘Äƒng kÃ½ doanh nghiá»‡p.', 'subpoints': []}, {'point': '5', 'text': '5. KÃª khai khá»‘ng vá»‘n Ä‘iá»u lá»‡ thÃ´ng qua hÃ nh vi khÃ´ng gÃ³p Ä‘á»§ sá»‘ vá»‘n Ä‘iá»u lá»‡ nhÆ° Ä‘Ã£ Ä‘Äƒng kÃ½ mÃ \\nkhÃ´ng thá»±c hiá»‡n Ä‘Äƒng kÃ½ Ä‘iá»u chá»‰nh vá»‘n Ä‘iá»u lá»‡ theo quy Ä‘á»‹nh cá»§a phÃ¡p luáº­t; cá»‘ Ã½ Ä‘á»‹nh giÃ¡ tÃ i sáº£n\\ngÃ³p vá»‘n khÃ´ng Ä‘Ãºng giÃ¡ trá»‹.â€.', 'subpoints': []}, {'point': '6', 'text': '6. Sá»­a Ä‘á»•i, bá»• sung má»™t sá»‘ Ä‘iá»ƒm, khoáº£n cá»§a Äiá»u 17 nhÆ° sau:', 'subpoints': [{'subpoint': 'a', 'text': 'a) Sá»­a Ä‘á»•i, bá»• sung Ä‘iá»ƒm b khoáº£n 2 nhÆ° sau:\\nâ€œb) CÃ¡n bá»™, cÃ´ng chá»©c, viÃªn chá»©c theo quy Ä‘á»‹nh cá»§a Luáº­t CÃ¡n bá»™, cÃ´ng chá»©c vÃ  Luáº­t ViÃªn chá»©c,\\ntrá»« trÆ°á»ng há»£p Ä‘Æ°á»£c thá»±c hiá»‡n theo quy Ä‘á»‹nh cá»§a phÃ¡p luáº­t vá» khoa há»c, cÃ´ng nghá»‡, Ä‘á»•i má»›i sÃ¡ng\\ntáº¡o vÃ  chuyá»ƒn Ä‘á»•i sá»‘ quá»‘c gia;â€;', 'subsubpoints': []}, {'subpoint': 'b', 'text': 'b) Sá»­a Ä‘á»•i, bá»• sung Ä‘iá»ƒm e khoáº£n 2 nhÆ° sau:\\nâ€œe) NgÆ°á»i Ä‘ang bá»‹ truy cá»©u trÃ¡ch nhiá»‡m hÃ¬nh sá»±, bá»‹ táº¡m giam, Ä‘ang cháº¥p hÃ nh hÃ¬nh pháº¡t tÃ¹, Ä‘ang\\ncháº¥p hÃ nh biá»‡n phÃ¡p xá»­ lÃ½ hÃ nh chÃ­nh táº¡i cÆ¡ sá»Ÿ cai nghiá»‡n báº¯t buá»™c, cÆ¡ sá»Ÿ giÃ¡o dá»¥c báº¯t buá»™c\\nhoáº·c Ä‘ang bá»‹ TÃ²a Ã¡n cáº¥m Ä‘áº£m nhiá»‡m chá»©c vá»¥, cáº¥m hÃ nh nghá» hoáº·c lÃ m cÃ´ng viá»‡c nháº¥t Ä‘á»‹nh; cÃ¡c\\ntrÆ°á»ng há»£p khÃ¡c theo quy Ä‘á»‹nh cá»§a Luáº­t PhÃ¡ sáº£n, Luáº­t PhÃ²ng, chá»‘ng tham nhÅ©ng;â€;', 'subsubpoints': []}, {'subpoint': 'c', 'text': 'c) Sá»­a Ä‘á»•i, bá»• sung Ä‘iá»ƒm b khoáº£n 3 nhÆ° sau:\\nâ€œb) Äá»‘i tÆ°á»£ng khÃ´ng Ä‘Æ°á»£c gÃ³p vá»‘n vÃ o doanh nghiá»‡p theo quy Ä‘á»‹nh cá»§a Luáº­t CÃ¡n bá»™, cÃ´ng chá»©c,\\nLuáº­t ViÃªn chá»©c vÃ  Luáº­t PhÃ²ng, chá»‘ng tham nhÅ©ng, trá»« trÆ°á»ng há»£p Ä‘Æ°á»£c thá»±c hiá»‡n theo quy Ä‘á»‹nh\\ncá»§a phÃ¡p luáº­t vá» khoa há»c, cÃ´ng nghá»‡, Ä‘á»•i má»›i sÃ¡ng táº¡o vÃ  chuyá»ƒn Ä‘á»•i sá»‘ quá»‘c gia.â€.', 'subsubpoints': []}]}, {'point': '7', 'text': '7. Sá»­a Ä‘á»•i, bá»• sung khoáº£n 3 Äiá»u 20 nhÆ° sau:\\nâ€œ3. Danh sÃ¡ch thÃ nh viÃªn; danh sÃ¡ch chá»§ sá»Ÿ há»¯u hÆ°á»Ÿng lá»£i cá»§a doanh nghiá»‡p (náº¿u cÃ³).â€.', 'subpoints': []}, {'point': '8', 'text': '8. Sá»­a Ä‘á»•i, bá»• sung khoáº£n 3 Äiá»u 21 nhÆ° sau:\\nâ€œ3. Danh sÃ¡ch thÃ nh viÃªn; danh sÃ¡ch chá»§ sá»Ÿ há»¯u hÆ°á»Ÿng lá»£i cá»§a doanh nghiá»‡p (náº¿u cÃ³).â€.', 'subpoints': []}, {'point': '9', 'text': '9. Sá»­a Ä‘á»•i, bá»• sung khoáº£n 3 Äiá»u 22 nhÆ° sau:\\nâ€œ3. Danh sÃ¡ch cá»• Ä‘Ã´ng sÃ¡ng láº­p; danh sÃ¡ch cá»• Ä‘Ã´ng lÃ  nhÃ  Ä‘áº§u tÆ° nÆ°á»›c ngoÃ i; danh sÃ¡ch chá»§ sá»Ÿ\\nhá»¯u hÆ°á»Ÿng lá»£i cá»§a doanh nghiá»‡p (náº¿u cÃ³).â€.', 'subpoints': []}, {'point': '10', 'text': '10. Bá»• sung khoáº£n 10 vÃ o sau khoáº£n 9 Äiá»u 23 nhÆ° sau:\\nâ€œ10. ThÃ´ng tin vá» chá»§ sá»Ÿ há»¯u hÆ°á»Ÿng lá»£i cá»§a doanh nghiá»‡p (náº¿u cÃ³).â€.', 'subpoints': []}, {'point': '11', 'text': '11. Sá»­a Ä‘á»•i, bá»• sung tÃªn Äiá»u, Ä‘oáº¡n má»Ÿ Ä‘áº§u cá»§a Äiá»u 25 vÃ  bá»• sung khoáº£n 5 vÃ o sau khoáº£n 4', 'subpoints': []}]}, {'clause': '25', 'text': 'Äiá»u 25 nhÆ° sau:\\na) Sá»­a Ä‘á»•i, bá»• sung tÃªn Äiá»u nhÆ° sau:\\nâ€œÄiá»u 25. Danh sÃ¡ch thÃ nh viÃªn cÃ´ng ty trÃ¡ch nhiá»‡m há»¯u háº¡n, cÃ´ng ty há»£p danh, danh sÃ¡ch\\ncá»• Ä‘Ã´ng sÃ¡ng láº­p vÃ  cá»• Ä‘Ã´ng lÃ  nhÃ  Ä‘áº§u tÆ° nÆ°á»›c ngoÃ i Ä‘á»‘i vá»›i cÃ´ng ty cá»• pháº§n, danh sÃ¡ch\\nchá»§ sá»Ÿ há»¯u hÆ°á»Ÿng lá»£i cá»§a doanh nghiá»‡p â€;\\nb) Sá»­a Ä‘á»•i, bá»• sung Ä‘oáº¡n má»Ÿ Ä‘áº§u nhÆ° sau:\\nâ€œDanh sÃ¡ch thÃ nh viÃªn cÃ´ng ty trÃ¡ch nhiá»‡m há»¯u háº¡n, cÃ´ng ty há»£p danh, danh sÃ¡ch cá»• Ä‘Ã´ng sÃ¡ng\\nláº­p vÃ  cá»• Ä‘Ã´ng lÃ  nhÃ  Ä‘áº§u tÆ° nÆ°á»›c ngoÃ i Ä‘á»‘i vá»›i cÃ´ng ty cá»• pháº§n, danh sÃ¡ch chá»§ sá»Ÿ há»¯u hÆ°á»Ÿng lá»£i\\ncá»§a doanh nghiá»‡p pháº£i bao gá»“m cÃ¡c ná»™i dung chá»§ yáº¿u sau Ä‘Ã¢y:â€;\\nc) Bá»• sung khoáº£n 5 vÃ o sau khoáº£n 4 nhÆ° sau:\\nâ€œ5. Danh sÃ¡ch chá»§ sá»Ÿ há»¯u hÆ°á»Ÿng lá»£i cá»§a doanh nghiá»‡p bao gá»“m cÃ¡c ná»™i dung chá»§ yáº¿u sau Ä‘Ã¢y:\\nhá», tÃªn; ngÃ y, thÃ¡ng, nÄƒm sinh; quá»‘c tá»‹ch; dÃ¢n tá»™c; giá»›i tÃ­nh; Ä‘á»‹a chá»‰ liÃªn láº¡c; tá»· lá»‡ sá»Ÿ há»¯u hoáº·c\\nquyá»n chi phá»‘i; thÃ´ng tin vá» giáº¥y tá» phÃ¡p lÃ½ cá»§a cÃ¡ nhÃ¢n chá»§ sá»Ÿ há»¯u hÆ°á»Ÿng lá»£i cá»§a doanh\\nnghiá»‡p.â€.', 'points': [{'point': '12', 'text': '12. Sá»­a Ä‘á»•i, bá»• sung, bÃ£i bá» má»™t sá»‘ khoáº£n cá»§a Äiá»u 26 nhÆ° sau:', 'subpoints': [{'subpoint': 'a', 'text': 'a) BÃ£i bá» khoáº£n 3 vÃ  khoáº£n 4;', 'subsubpoints': []}, {'subpoint': 'b', 'text': 'b) Sá»­a Ä‘á»•i, bá»• sung khoáº£n 6 nhÆ° sau:\\nâ€œ6. ChÃ­nh phá»§ quy Ä‘á»‹nh vá» há»“ sÆ¡, trÃ¬nh tá»±, thá»§ tá»¥c, liÃªn thÃ´ng trong Ä‘Äƒng kÃ½ doanh nghiá»‡p, viá»‡c\\nÄ‘Äƒng kÃ½ doanh nghiá»‡p qua máº¡ng thÃ´ng tin Ä‘iá»‡n tá»­.â€.', 'subsubpoints': []}]}, {'point': '13', 'text': '13. Sá»­a Ä‘á»•i, bá»• sung khoáº£n 1 Äiá»u 31 nhÆ° sau:\\nâ€œ1. Doanh nghiá»‡p pháº£i thÃ´ng bÃ¡o vá»›i CÆ¡ quan Ä‘Äƒng kÃ½ kinh doanh khi cÃ³ thay Ä‘á»•i má»™t trong cÃ¡c\\nná»™i dung sau Ä‘Ã¢y:', 'subpoints': [{'subpoint': 'a', 'text': 'a) NgÃ nh, nghá» kinh doanh;', 'subsubpoints': []}, {'subpoint': 'b', 'text': 'b) Cá»• Ä‘Ã´ng sÃ¡ng láº­p vÃ  cá»• Ä‘Ã´ng lÃ  nhÃ  Ä‘áº§u tÆ° nÆ°á»›c ngoÃ i Ä‘á»‘i vá»›i cÃ´ng ty cá»• pháº§n, trá»« trÆ°á»ng há»£p\\nÄ‘á»‘i vá»›i cÃ´ng ty niÃªm yáº¿t vÃ  cÃ´ng ty Ä‘Äƒng kÃ½ giao dá»‹ch chá»©ng khoÃ¡n;', 'subsubpoints': []}, {'subpoint': 'c', 'text': 'c) ThÃ´ng tin vá» chá»§ sá»Ÿ há»¯u hÆ°á»Ÿng lá»£i cá»§a doanh nghiá»‡p, trá»« trÆ°á»ng há»£p Ä‘á»‘i vá»›i cÃ´ng ty niÃªm yáº¿t\\nvÃ  cÃ´ng ty Ä‘Äƒng kÃ½ giao dá»‹ch chá»©ng khoÃ¡n;', 'subsubpoints': []}, {'subpoint': 'd', 'text': 'd) Ná»™i dung khÃ¡c trong há»“ sÆ¡ Ä‘Äƒng kÃ½ doanh nghiá»‡p.â€.', 'subsubpoints': []}]}, {'point': '14', 'text': '14. Bá»• sung khoáº£n 1a vÃ o sau khoáº£n 1 Äiá»u 33 nhÆ° sau:\\nâ€œ1a. CÆ¡ quan nhÃ  nÆ°á»›c cÃ³ tháº©m quyá»n theo quy Ä‘á»‹nh cá»§a phÃ¡p luáº­t cÃ³ quyá»n Ä‘á» nghá»‹ CÆ¡ quan\\nquáº£n lÃ½ nhÃ  nÆ°á»›c vá» Ä‘Äƒng kÃ½ kinh doanh cung cáº¥p thÃ´ng tin vá» chá»§ sá»Ÿ há»¯u hÆ°á»Ÿng lá»£i cá»§a doanh\\nnghiá»‡p Ä‘Æ°á»£c lÆ°u giá»¯ trÃªn Há»‡ thá»‘ng thÃ´ng tin quá»‘c gia vá» Ä‘Äƒng kÃ½ doanh nghiá»‡p Ä‘á»ƒ phá»¥c vá»¥ cÃ´ng\\ntÃ¡c vá» phÃ²ng, chá»‘ng rá»­a tiá»n vÃ  khÃ´ng pháº£i tráº£ phÃ­.â€.', 'subpoints': []}, {'point': '15', 'text': '15. Sá»­a Ä‘á»•i, bá»• sung Ä‘iá»ƒm a khoáº£n 1 Äiá»u 52 nhÆ° sau:\\nâ€œa) ChÃ o bÃ¡n pháº§n vá»‘n gÃ³p Ä‘Ã³ cho thÃ nh viÃªn cÃ²n láº¡i theo tá»· lá»‡ tÆ°Æ¡ng á»©ng vá»›i pháº§n vá»‘n gÃ³p cá»§a\\nthÃ nh viÃªn cÃ²n láº¡i trong cÃ´ng ty vá»›i cÃ¹ng Ä‘iá»u kiá»‡n chÃ o bÃ¡n;â€.', 'subpoints': []}, {'point': '16', 'text': '16. Bá»• sung khoáº£n 9 vÃ o sau khoáº£n 8 Äiá»u 57 nhÆ° sau:\\nâ€œ9. Ná»™i dung liÃªn quan Ä‘áº¿n trÃ¬nh tá»±, thá»§ tá»¥c má»i há»p, triá»‡u táº­p há»p Há»™i Ä‘á»“ng thÃ nh viÃªn trong\\ntrÆ°á»ng há»£p quy Ä‘á»‹nh táº¡i khoáº£n 4 Äiá»u 56 thá»±c hiá»‡n tÆ°Æ¡ng á»©ng theo cÃ¡c quy Ä‘á»‹nh táº¡i cÃ¡c khoáº£n 2,\\n3, 4, 5 vÃ  6 Äiá»u nÃ y. Chi phÃ­ há»£p lÃ½ cho viá»‡c triá»‡u táº­p vÃ  tiáº¿n hÃ nh há»p Há»™i Ä‘á»“ng thÃ nh viÃªn sáº½\\nÄ‘Æ°á»£c cÃ´ng ty hoÃ n láº¡i.â€.', 'subpoints': []}, {'point': '17', 'text': '17. Sá»­a Ä‘á»•i, bá»• sung má»™t sá»‘ Ä‘iá»ƒm cá»§a khoáº£n 5 Äiá»u 112 nhÆ° sau:', 'subpoints': [{'subpoint': 'a', 'text': 'a) Sá»­a Ä‘á»•i, bá»• sung Ä‘iá»ƒm a nhÆ° sau:\\nâ€œa) Theo quyáº¿t Ä‘á»‹nh cá»§a Äáº¡i há»™i Ä‘á»“ng cá»• Ä‘Ã´ng, cÃ´ng ty hoÃ n tráº£ má»™t pháº§n vá»‘n gÃ³p cho cá»• Ä‘Ã´ng\\ntheo tá»· lá»‡ sá»Ÿ há»¯u cá»• pháº§n cá»§a há» trong cÃ´ng ty náº¿u cÃ´ng ty Ä‘Ã£ hoáº¡t Ä‘á»™ng kinh doanh tá»« 02 nÄƒm\\ntrá»Ÿ lÃªn ká»ƒ tá»« ngÃ y Ä‘Äƒng kÃ½ thÃ nh láº­p doanh nghiá»‡p khÃ´ng ká»ƒ thá»i gian Ä‘Äƒng kÃ½ táº¡m ngá»«ng kinh\\ndoanh vÃ  báº£o Ä‘áº£m thanh toÃ¡n Ä‘á»§ cÃ¡c khoáº£n ná»£ vÃ  nghÄ©a vá»¥ tÃ i sáº£n khÃ¡c sau khi Ä‘Ã£ hoÃ n tráº£ cho\\ncá»• Ä‘Ã´ng;â€;', 'subsubpoints': []}, {'subpoint': 'b', 'text': 'b) Bá»• sung Ä‘iá»ƒm d vÃ o sau Ä‘iá»ƒm c nhÆ° sau:\\nâ€œd) CÃ´ng ty hoÃ n láº¡i vá»‘n gÃ³p theo yÃªu cáº§u, Ä‘iá»u kiá»‡n Ä‘Æ°á»£c ghi táº¡i cá»• phiáº¿u cho cá»• Ä‘Ã´ng sá»Ÿ há»¯u\\ncá»• pháº§n cÃ³ quyá»n Æ°u Ä‘Ã£i hoÃ n láº¡i theo quy Ä‘á»‹nh cá»§a Luáº­t nÃ y vÃ  Äiá»u lá»‡ cÃ´ng ty.â€.', 'subsubpoints': []}]}, {'point': '18', 'text': '18. Sá»­a Ä‘á»•i, bá»• sung khoáº£n 4 Äiá»u 115 nhÆ° sau:\\nâ€œ4. YÃªu cáº§u triá»‡u táº­p há»p Äáº¡i há»™i Ä‘á»“ng cá»• Ä‘Ã´ng quy Ä‘á»‹nh táº¡i khoáº£n 3 Äiá»u nÃ y pháº£i báº±ng vÄƒn báº£n\\nvÃ  pháº£i bao gá»“m cÃ¡c ná»™i dung sau Ä‘Ã¢y: há», tÃªn, Ä‘á»‹a chá»‰ liÃªn láº¡c, quá»‘c tá»‹ch, sá»‘ giáº¥y tá» phÃ¡p lÃ½ cá»§a\\ncÃ¡ nhÃ¢n Ä‘á»‘i vá»›i cá»• Ä‘Ã´ng lÃ  cÃ¡ nhÃ¢n; tÃªn, mÃ£ sá»‘ doanh nghiá»‡p hoáº·c sá»‘ giáº¥y tá» phÃ¡p lÃ½ cá»§a tá»• chá»©c,\\nÄ‘á»‹a chá»‰ trá»¥ sá»Ÿ chÃ­nh Ä‘á»‘i vá»›i cá»• Ä‘Ã´ng lÃ  tá»• chá»©c; sá»‘ lÆ°á»£ng cá»• pháº§n vÃ  thá»i Ä‘iá»ƒm Ä‘Äƒng kÃ½ cá»• pháº§n\\ncá»§a tá»«ng cá»• Ä‘Ã´ng, tá»•ng sá»‘ cá»• pháº§n cá»§a cáº£ nhÃ³m cá»• Ä‘Ã´ng vÃ  tá»· lá»‡ sá»Ÿ há»¯u trong tá»•ng sá»‘ cá»• pháº§n\\ncá»§a cÃ´ng ty, cÄƒn cá»© vÃ  lÃ½ do yÃªu cáº§u triá»‡u táº­p há»p Äáº¡i há»™i Ä‘á»“ng cá»• Ä‘Ã´ng. KÃ¨m theo yÃªu cáº§u triá»‡u\\ntáº­p há»p pháº£i cÃ³ cÃ¡c tÃ i liá»‡u, chá»©ng cá»© vá» cÃ¡c vi pháº¡m cá»§a Há»™i Ä‘á»“ng quáº£n trá»‹, má»©c Ä‘á»™ vi pháº¡m\\nhoáº·c vá» quyáº¿t Ä‘á»‹nh vÆ°á»£t quÃ¡ tháº©m quyá»n. Cá»• Ä‘Ã´ng hoáº·c nhÃ³m cá»• Ä‘Ã´ng chá»‹u hoÃ n toÃ n trÃ¡ch\\nnhiá»‡m trÆ°á»›c phÃ¡p luáº­t vá» tÃ­nh chÃ­nh xÃ¡c, trung thá»±c cá»§a cÃ¡c tÃ i liá»‡u, chá»©ng cá»© cung cáº¥p cho cÆ¡\\nquan cÃ³ tháº©m quyá»n khi yÃªu cáº§u triá»‡u táº­p há»p Äáº¡i há»™i Ä‘á»“ng cá»• Ä‘Ã´ng.â€.', 'subpoints': []}, {'point': '19', 'text': '19. Sá»­a Ä‘á»•i, bá»• sung má»™t sá»‘ Ä‘iá»ƒm, khoáº£n cá»§a Äiá»u 128 nhÆ° sau:', 'subpoints': [{'subpoint': 'a', 'text': 'a) Sá»­a Ä‘á»•i, bá»• sung Ä‘iá»ƒm b khoáº£n 2 nhÆ° sau:\\nâ€œb) NhÃ  Ä‘áº§u tÆ° chá»©ng khoÃ¡n chuyÃªn nghiá»‡p tham gia mua, giao dá»‹ch, chuyá»ƒn nhÆ°á»£ng trÃ¡i phiáº¿u\\nriÃªng láº» thá»±c hiá»‡n theo quy Ä‘á»‹nh phÃ¡p luáº­t vá» chá»©ng khoÃ¡n.â€;', 'subsubpoints': []}, {'subpoint': 'b', 'text': 'b) Bá»• sung Ä‘iá»ƒm c1 vÃ o sau Ä‘iá»ƒm c khoáº£n 3 nhÆ° sau:\\nâ€œc1) CÃ³ ná»£ pháº£i tráº£ (bao gá»“m giÃ¡ trá»‹ trÃ¡i phiáº¿u dá»± kiáº¿n phÃ¡t hÃ nh) khÃ´ng vÆ°á»£t quÃ¡ 05 láº§n vá»‘n chá»§\\nsá»Ÿ há»¯u cá»§a tá»• chá»©c phÃ¡t hÃ nh theo bÃ¡o cÃ¡o tÃ i chÃ­nh nÄƒm liá»n ká» trÆ°á»›c nÄƒm phÃ¡t hÃ nh Ä‘Æ°á»£c kiá»ƒm\\ntoÃ¡n; trá»« tá»• chá»©c phÃ¡t hÃ nh lÃ  doanh nghiá»‡p nhÃ  nÆ°á»›c, doanh nghiá»‡p phÃ¡t hÃ nh trÃ¡i phiáº¿u Ä‘á»ƒ thá»±c\\nhiá»‡n dá»± Ã¡n báº¥t Ä‘á»™ng sáº£n, tá»• chá»©c tÃ­n dá»¥ng, doanh nghiá»‡p báº£o hiá»ƒm, doanh nghiá»‡p tÃ¡i báº£o hiá»ƒm,\\ndoanh nghiá»‡p mÃ´i giá»›i báº£o hiá»ƒm, cÃ´ng ty chá»©ng khoÃ¡n, cÃ´ng ty quáº£n lÃ½ quá»¹ Ä‘áº§u tÆ° chá»©ng khoÃ¡n\\nthá»±c hiá»‡n theo quy Ä‘á»‹nh cá»§a phÃ¡p luáº­t cÃ³ liÃªn quan;â€.', 'subsubpoints': []}]}, {'point': '20', 'text': '20. Bá»• sung khoáº£n 4a vÃ o sau khoáº£n 4 Äiá»u 140 nhÆ° sau:\\nâ€œ4a. Äá»‘i vá»›i cÃ´ng ty cÃ³ cÆ¡ cáº¥u tá»• chá»©c quáº£n lÃ½ theo quy Ä‘á»‹nh táº¡i Ä‘iá»ƒm b khoáº£n 1 Äiá»u 137,\\ntrÆ°á»ng há»£p Há»™i Ä‘á»“ng quáº£n trá»‹ khÃ´ng triá»‡u táº­p há»p Äáº¡i há»™i Ä‘á»“ng cá»• Ä‘Ã´ng theo quy Ä‘á»‹nh táº¡i khoáº£n\\n2 Äiá»u nÃ y thÃ¬ trong thá»i háº¡n 30 ngÃ y tiáº¿p theo, cá»• Ä‘Ã´ng hoáº·c nhÃ³m cá»• Ä‘Ã´ng theo quy Ä‘á»‹nh táº¡i\\nkhoáº£n 2 Äiá»u 115 cá»§a Luáº­t nÃ y cÃ³ quyá»n Ä‘áº¡i diá»‡n cÃ´ng ty triá»‡u táº­p há»p Äáº¡i há»™i Ä‘á»“ng cá»• Ä‘Ã´ng\\ntheo quy Ä‘á»‹nh cá»§a Luáº­t nÃ y. Chi phÃ­ há»£p lÃ½ cho viá»‡c triá»‡u táº­p vÃ  tiáº¿n hÃ nh há»p Äáº¡i há»™i Ä‘á»“ng cá»•\\nÄ‘Ã´ng sáº½ Ä‘Æ°á»£c cÃ´ng ty hoÃ n láº¡i.â€.', 'subpoints': []}, {'point': '21', 'text': '21. Sá»­a Ä‘á»•i, bá»• sung khoáº£n 1 Äiá»u 141 nhÆ° sau:\\nâ€œ1. Danh sÃ¡ch cá»• Ä‘Ã´ng cÃ³ quyá»n dá»± há»p Äáº¡i há»™i Ä‘á»“ng cá»• Ä‘Ã´ng Ä‘Æ°á»£c láº­p dá»±a trÃªn sá»• Ä‘Äƒng kÃ½ cá»•\\nÄ‘Ã´ng, sá»• Ä‘Äƒng kÃ½ ngÆ°á»i sá»Ÿ há»¯u chá»©ng khoÃ¡n cá»§a cÃ´ng ty. Danh sÃ¡ch cá»• Ä‘Ã´ng cÃ³ quyá»n dá»± há»p\\nÄáº¡i há»™i Ä‘á»“ng cá»• Ä‘Ã´ng Ä‘Æ°á»£c láº­p khÃ´ng quÃ¡ 10 ngÃ y trÆ°á»›c ngÃ y gá»­i giáº¥y má»i há»p Äáº¡i há»™i Ä‘á»“ng cá»•\\nÄ‘Ã´ng náº¿u Äiá»u lá»‡ cÃ´ng ty khÃ´ng quy Ä‘á»‹nh thá»i háº¡n ngáº¯n hÆ¡n.â€.', 'subpoints': []}, {'point': '22', 'text': '22. Sá»­a Ä‘á»•i, bá»• sung khoáº£n 3 Äiá»u 176 nhÆ° sau:\\nâ€œ3. CÃ´ng ty cá»• pháº§n, trá»« cÃ´ng ty niÃªm yáº¿t vÃ  cÃ´ng ty Ä‘Äƒng kÃ½ giao dá»‹ch chá»©ng khoÃ¡n, pháº£i thÃ´ng\\nbÃ¡o cho CÆ¡ quan Ä‘Äƒng kÃ½ kinh doanh cháº­m nháº¥t lÃ  03 ngÃ y lÃ m viá»‡c sau khi cÃ³ thÃ´ng tin hoáº·c cÃ³\\nthay Ä‘á»•i cÃ¡c thÃ´ng tin vá» há», tÃªn, quá»‘c tá»‹ch, sá»‘ há»™ chiáº¿u, Ä‘á»‹a chá»‰ liÃªn láº¡c, sá»‘ cá»• pháº§n vÃ  loáº¡i cá»•\\npháº§n cá»§a cá»• Ä‘Ã´ng lÃ  cÃ¡ nhÃ¢n nÆ°á»›c ngoÃ i; tÃªn, mÃ£ sá»‘ doanh nghiá»‡p, Ä‘á»‹a chá»‰ trá»¥ sá»Ÿ chÃ­nh, sá»‘ cá»•\\npháº§n vÃ  loáº¡i cá»• pháº§n cá»§a cá»• Ä‘Ã´ng lÃ  tá»• chá»©c nÆ°á»›c ngoÃ i vÃ  há», tÃªn, quá»‘c tá»‹ch, sá»‘ há»™ chiáº¿u, Ä‘á»‹a chá»‰\\nliÃªn láº¡c ngÆ°á»i Ä‘áº¡i diá»‡n theo á»§y quyá»n cá»§a cá»• Ä‘Ã´ng lÃ  tá»• chá»©c nÆ°á»›c ngoÃ i.â€.', 'subpoints': []}, {'point': '23', 'text': '23. Sá»­a Ä‘á»•i, bá»• sung Ä‘iá»ƒm c khoáº£n 1 Äiá»u 207 nhÆ° sau:\\nâ€œc) CÃ´ng ty khÃ´ng cÃ²n Ä‘á»§ sá»‘ lÆ°á»£ng thÃ nh viÃªn, cá»• Ä‘Ã´ng tá»‘i thiá»ƒu theo quy Ä‘á»‹nh cá»§a Luáº­t nÃ y\\ntrong thá»i háº¡n 06 thÃ¡ng liÃªn tá»¥c mÃ  khÃ´ng lÃ m thá»§ tá»¥c chuyá»ƒn Ä‘á»•i loáº¡i hÃ¬nh doanh nghiá»‡p;â€.', 'subpoints': []}, {'point': '24', 'text': '24. Sá»­a Ä‘á»•i, bá»• sung khoáº£n 1 Äiá»u 213 nhÆ° sau:\\nâ€œ1. Chi nhÃ¡nh, vÄƒn phÃ²ng Ä‘áº¡i diá»‡n, Ä‘á»‹a Ä‘iá»ƒm kinh doanh cá»§a doanh nghiá»‡p Ä‘Æ°á»£c cháº¥m dá»©t hoáº¡t\\nÄ‘á»™ng theo quyáº¿t Ä‘á»‹nh cá»§a chÃ­nh doanh nghiá»‡p Ä‘Ã³ hoáº·c theo quyáº¿t Ä‘á»‹nh thu há»“i Giáº¥y chá»©ng nháº­n\\nÄ‘Äƒng kÃ½ doanh nghiá»‡p, hoáº¡t Ä‘á»™ng chi nhÃ¡nh, vÄƒn phÃ²ng Ä‘áº¡i diá»‡n, Ä‘á»‹a Ä‘iá»ƒm kinh doanh cá»§a cÆ¡\\nquan nhÃ  nÆ°á»›c cÃ³ tháº©m quyá»n.â€.', 'subpoints': []}, {'point': '25', 'text': '25. Sá»­a Ä‘á»•i, bá»• sung má»™t sá»‘ Ä‘iá»ƒm, khoáº£n cá»§a Äiá»u 215 nhÆ° sau:', 'subpoints': [{'subpoint': 'a', 'text': 'a) Sá»­a Ä‘á»•i, bá»• sung khoáº£n 3 nhÆ° sau:\\nâ€œ3. á»¦y ban nhÃ¢n dÃ¢n cáº¥p tá»‰nh thá»±c hiá»‡n quáº£n lÃ½ nhÃ  nÆ°á»›c Ä‘á»‘i vá»›i doanh nghiá»‡p trong pháº¡m vi Ä‘á»‹a\\nphÆ°Æ¡ng, cÃ³ trÃ¡ch nhiá»‡m tá»• chá»©c CÆ¡ quan Ä‘Äƒng kÃ½ kinh doanh, ban hÃ nh quy trÃ¬nh kiá»ƒm tra ná»™i\\ndung vá» Ä‘Äƒng kÃ½ kinh doanh trÃªn Ä‘á»‹a bÃ n báº£o Ä‘áº£m cÃ´ng khai, minh báº¡ch.â€;', 'subsubpoints': []}, {'subpoint': 'b', 'text': 'b) Sá»­a Ä‘á»•i, bá»• sung Ä‘iá»ƒm c khoáº£n 4 nhÆ° sau:\\nâ€œc) Phá»‘i há»£p, chia sáº» thÃ´ng tin vá» tÃ¬nh hÃ¬nh hoáº¡t Ä‘á»™ng cá»§a doanh nghiá»‡p, tÃ¬nh tráº¡ng phÃ¡p lÃ½ cá»§a\\ndoanh nghiá»‡p Ä‘á»ƒ nÃ¢ng cao hiá»‡u lá»±c quáº£n lÃ½ nhÃ  nÆ°á»›c.â€;', 'subsubpoints': []}, {'subpoint': 'c', 'text': 'c) Bá»• sung khoáº£n 4a vÃ o sau khoáº£n 4 nhÆ° sau:\\nâ€œ4a. TrÆ°á»ng há»£p doanh nghiá»‡p Ä‘Æ°á»£c thÃ nh láº­p vÃ  hoáº¡t Ä‘á»™ng theo luáº­t quáº£n lÃ½ ngÃ nh, lÄ©nh vá»±c thÃ¬\\ncÆ¡ quan cáº¥p Ä‘Äƒng kÃ½ cÃ³ trÃ¡ch nhiá»‡m tÃ­ch há»£p, chia sáº», cáº­p nháº­t thÃ´ng tin vá» Ä‘Äƒng kÃ½, thÃ nh láº­p\\ndoanh nghiá»‡p vá»›i Há»‡ thá»‘ng thÃ´ng tin quá»‘c gia vá» Ä‘Äƒng kÃ½ doanh nghiá»‡p.â€.', 'subsubpoints': []}]}, {'point': '26', 'text': '26. Bá»• sung Ä‘iá»ƒm h vÃ o sau Ä‘iá»ƒm g khoáº£n 1 Äiá»u 216 nhÆ° sau:\\nâ€œh) LÆ°u giá»¯ thÃ´ng tin vá» chá»§ sá»Ÿ há»¯u hÆ°á»Ÿng lá»£i cá»§a doanh nghiá»‡p Ã­t nháº¥t 05 nÄƒm ká»ƒ tá»« ngÃ y\\ndoanh nghiá»‡p giáº£i thá»ƒ, phÃ¡ sáº£n theo quy Ä‘á»‹nh cá»§a phÃ¡p luáº­t.â€.', 'subpoints': []}, {'point': '27', 'text': '27. Bá»• sung khoáº£n 6 vÃ o sau khoáº£n 5 Äiá»u 217 nhÆ° sau:\\nâ€œ6. ChÃ­nh phá»§ quy Ä‘á»‹nh chi tiáº¿t tiÃªu chÃ­ xÃ¡c Ä‘á»‹nh, chá»§ thá»ƒ kÃª khai vÃ  viá»‡c kÃª khai thÃ´ng tin vá» chá»§\\nsá»Ÿ há»¯u hÆ°á»Ÿng lá»£i cá»§a doanh nghiá»‡p, thÃ´ng tin Ä‘á»ƒ xÃ¡c Ä‘á»‹nh chá»§ sá»Ÿ há»¯u hÆ°á»Ÿng lá»£i cá»§a doanh\\nnghiá»‡p, cung cáº¥p, lÆ°u giá»¯, chia sáº» thÃ´ng tin vá» chá»§ sá»Ÿ há»¯u hÆ°á»Ÿng lá»£i cá»§a doanh nghiá»‡p.â€.', 'subpoints': []}, {'point': '28', 'text': '28. Thay tháº¿ tá»« â€œsÃ¡ch nhiá»…uâ€ báº±ng tá»« â€œnhÅ©ng nhiá»…uâ€ táº¡i khoáº£n 1 Äiá»u 16.', 'subpoints': []}]}, {'clause': '2', 'text': 'Äiá»u 2. Hiá»‡u lá»±c thi hÃ nh\\nLuáº­t nÃ y cÃ³ hiá»‡u lá»±c thi hÃ nh tá»« ngÃ y 01 thÃ¡ng 7 nÄƒm 2025.', 'points': []}, {'clause': '3', 'text': 'Äiá»u 3. Äiá»u khoáº£n chuyá»ƒn tiáº¿p', 'points': [{'point': '1', 'text': '1. Äá»‘i vá»›i doanh nghiá»‡p Ä‘Æ°á»£c Ä‘Äƒng kÃ½ thÃ nh láº­p trÆ°á»›c thá»i Ä‘iá»ƒm Luáº­t nÃ y cÃ³ hiá»‡u lá»±c thi hÃ nh\\nthÃ¬ viá»‡c bá»• sung thÃ´ng tin vá» chá»§ sá»Ÿ há»¯u hÆ°á»Ÿng lá»£i cá»§a doanh nghiá»‡p (náº¿u cÃ³), thÃ´ng tin Ä‘á»ƒ xÃ¡c\\nÄ‘á»‹nh chá»§ sá»Ÿ há»¯u hÆ°á»Ÿng lá»£i cá»§a doanh nghiá»‡p (náº¿u cÃ³) Ä‘Æ°á»£c thá»±c hiá»‡n Ä‘á»“ng thá»i táº¡i thá»i Ä‘iá»ƒm\\ndoanh nghiá»‡p thá»±c hiá»‡n thá»§ tá»¥c Ä‘Äƒng kÃ½ thay Ä‘á»•i ná»™i dung Ä‘Äƒng kÃ½ doanh nghiá»‡p, thÃ´ng bÃ¡o thay\\nÄ‘á»•i ná»™i dung Ä‘Äƒng kÃ½ doanh nghiá»‡p gáº§n nháº¥t, trá»« trÆ°á»ng há»£p doanh nghiá»‡p cÃ³ yÃªu cáº§u bá»• sung\\nthÃ´ng tin sá»›m hÆ¡n.', 'subpoints': []}, {'point': '2', 'text': '2. Äá»‘i vá»›i cÃ¡c Ä‘á»£t chÃ o bÃ¡n trÃ¡i phiáº¿u doanh nghiá»‡p riÃªng láº» Ä‘Ã£ gá»­i ná»™i dung cÃ´ng bá»‘ thÃ´ng tin\\ntrÆ°á»›c Ä‘á»£t chÃ o bÃ¡n cho Sá»Ÿ giao dá»‹ch chá»©ng khoÃ¡n trÆ°á»›c ngÃ y Luáº­t nÃ y cÃ³ hiá»‡u lá»±c thi hÃ nh thÃ¬\\ntiáº¿p tá»¥c thá»±c hiá»‡n theo quy Ä‘á»‹nh cá»§a Luáº­t Doanh nghiá»‡p sá»‘ 59/2020/QH14 Ä‘Ã£ Ä‘Æ°á»£c sá»­a Ä‘á»•i, bá»•\\nsung má»™t sá»‘ Ä‘iá»u theo Luáº­t sá»‘ 03/2022/QH15.\\nLuáº­t nÃ y Ä‘Æ°á»£c Quá»‘c há»™i nÆ°á»›c Cá»™ng hÃ²a xÃ£ há»™i chá»§ nghÄ©a Viá»‡t Nam khÃ³a XV, Ká»³ há»p thá»© 9\\nthÃ´ng qua ngÃ y 17 thÃ¡ng 6 nÄƒm 2025.\\nCHá»¦ Tá»ŠCH QUá»C Há»˜I\\nTráº§n Thanh Máº«n', 'subpoints': []}]}]})\n"
     ]
    }
   ],
   "source": [
    "print(parse_legal_text(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae1fd41",
   "metadata": {},
   "source": [
    "#### saving_neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f54df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving_neo4j(text, namespace=\"Test\"):\n",
    "    type_dict = {\n",
    "            \"Luáº­t\": 1,\n",
    "            \"Nghá»‹ Äá»‹nh\":2,\n",
    "            \"Nghá»‹ Quyáº¿t\":3,\n",
    "            \"Quyáº¿t Äá»‹nh\":4,\n",
    "            \"ThÃ´ng TÆ°\":5\n",
    "        }\n",
    "   # Extract metadata\n",
    "    df_meta = ner.extract_document_metadata(text)\n",
    "    \n",
    "    doc_type = df_meta['document_type'].iloc[0]\n",
    "    \n",
    "    df_relation = final_re.final_relation(text)\n",
    "    df_meta['document_type'] = df_meta['document_type'].apply(lambda x: type_dict[x])\n",
    "    df_meta['amend'] = df_meta['amend'].apply(lambda x: 0 if x == False else 1)\n",
    "    meta_row = df_meta.iloc[0]\n",
    "    self_check = {'luáº­t': 'doc1', 'Ä‘á»‹nh': 'doc2', 'tÆ°': 'doc3', 'quyáº¿t': 'doc4', 'chÆ°Æ¡ng': 'chapter', 'Ä‘iá»u': 'clause', 'má»¥c': 'point'}\n",
    "\n",
    "    metadata = {\n",
    "        \"law_id\": meta_row[\"document_id\"],\n",
    "        \"document_type\": meta_row[\"document_type\"],\n",
    "        \"amend\":meta_row['amend']\n",
    "    }\n",
    "\n",
    "    # Document type\n",
    "    doc_type_label = doc_type.replace(\" \", \"_\").capitalize()\n",
    "    # Namespace\n",
    "    ns_label = re.sub(r\"\\W+\", \"_\", namespace)\n",
    "\n",
    "    # central document node\n",
    "    dml_ddl_neo4j(\n",
    "        f\"\"\"\n",
    "        MERGE (l:`{doc_type_label}`:`{ns_label}` {{id: $law_id}})\n",
    "        SET l += $meta\n",
    "        \"\"\",\n",
    "        law_id=metadata[\"law_id\"],\n",
    "        meta=metadata,\n",
    "    )\n",
    "    \n",
    "    #Connect reference node\n",
    "    for i in range(len(df_relation)):\n",
    "        \n",
    "        doc_type = df_relation.iloc[i,7].replace(\" \", \"_\").capitalize()\n",
    "        \n",
    "        if (len(df_relation.iloc[i,6].split('/')) > 1) and (df_relation.iloc[i,7]):\n",
    "            \n",
    "            dml_ddl_neo4j(\n",
    "            f\"\"\"\n",
    "            MERGE (l:`{doc_type}`:`{ns_label}` {{id: $law_id}})\n",
    "            WITH l\n",
    "            MATCH (r: `{doc_type_label}`:`{ns_label}` {{id: $law_id2}})\n",
    "            MERGE (r)-[:`{df_relation.iloc[i,2]}`]->(l)\n",
    "            \"\"\",\n",
    "            law_id=df_relation.iloc[i,6],\n",
    "            law_id2=metadata['law_id']\n",
    "        )\n",
    "            if (df_relation.iloc[i,4]):  \n",
    "                dml_ddl_neo4j(\n",
    "                    f\"\"\"\n",
    "                    MATCH (l:`{doc_type}`:`{ns_label}` {{id: $law_id}})\n",
    "                    SET l.issue_date = $issue_date\n",
    "                    \"\"\",\n",
    "                    law_id=df_relation.iloc[i,6],\n",
    "                    issue_date=str(df_relation.iloc[i,4])\n",
    "                )\n",
    "                \n",
    "        #if id not available, use date\n",
    "        if df_relation.iloc[i,4]:\n",
    "            dml_ddl_neo4j(\n",
    "            f\"\"\"\n",
    "            MERGE (l:`{doc_type}`:`{ns_label}` {{issue_date: $issue_date}})\n",
    "            WITH l\n",
    "            MATCH (r: `{doc_type_label}`:`{ns_label}` {{id: $law_id2}})\n",
    "            MERGE (r)-[:`{df_relation.iloc[i,2]}`]->(l)\n",
    "            \"\"\",\n",
    "            issue_date=str(df_relation.iloc[i,4]),\n",
    "            law_id2=metadata['law_id']\n",
    "        )\n",
    "            \n",
    "    # Parse structure\n",
    "    parsed = parse_legal_text(text)\n",
    "\n",
    "    # Extract text\n",
    "    def get_text(node, *keys):\n",
    "        for k in keys:\n",
    "            if isinstance(node, dict) and k in node and node[k]:\n",
    "                return node[k]\n",
    "        if isinstance(node, str):\n",
    "            return node\n",
    "        return \"\"\n",
    "\n",
    "    # If HAS chapters \n",
    "    if \"chapters\" in parsed:\n",
    "        for chapter_key, chapter_obj in parsed[\"chapters\"].items():\n",
    "            chapter_id = f\"{metadata['law_id']}_{chapter_key.replace(' ', '_')}\"\n",
    "            chapter_title = get_text(chapter_obj, \"title\")\n",
    "            chapter_text = get_text(chapter_obj, \"text\")\n",
    "            re_text = None\n",
    "            re_temp = None\n",
    "            relation = None\n",
    "            second_entity = []\n",
    "                          \n",
    "            dml_ddl_neo4j(\n",
    "                f\"\"\"\n",
    "                MERGE (ch:Chapter:{ns_label} {{id: $id}})\n",
    "                SET ch.title = $title, ch.text = $text, ch.original_embedding = $embed\n",
    "                WITH ch\n",
    "                MATCH (l:{ns_label} {{law_id: $law_id}})\n",
    "                MERGE (l)-[:HAS_CHAPTER]->(ch)\n",
    "                \"\"\",\n",
    "                id=chapter_id,\n",
    "                title=chapter_title,\n",
    "                text=chapter_text,\n",
    "                law_id=metadata[\"law_id\"],\n",
    "                embed = text_embedding(chapter_text, 3, phobert)\n",
    "            )\n",
    "                    \n",
    "            #Extract relation\n",
    "            chapter_text = re.sub(r'^(ChÆ°Æ¡ng|Äiá»u)\\s*\\d*\\s*', '', chapter_text, flags=re.IGNORECASE)\n",
    "            re_text = sent_tokenize(chapter_text)\n",
    "            for sentence in re_text:\n",
    "                root = None\n",
    "                re_temp = final_re.final_relation(sentence)\n",
    "\n",
    "                if len(re_temp['document_id']) > 0:\n",
    "                    _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "\n",
    "                if 'nÃ y' in sentence.split():\n",
    "                    words = sentence.split()\n",
    "                    root = None\n",
    "                    ref = None\n",
    "                    for i, token in enumerate(words):\n",
    "                        if token == \"nÃ y\" and i > 0:\n",
    "                            prev_word = words[i-1]\n",
    "                            if prev_word.lower() in self_check.keys():\n",
    "                                text_type = self_check[prev_word.lower()]\n",
    "                                match text_type:\n",
    "                                    case \"doc1\":\n",
    "                                        root = metadata[\"law_id\"]\n",
    "                                        ref = \"Luáº­t\"\n",
    "                                    case \"doc2\":\n",
    "                                        root = metadata[\"law_id\"]\n",
    "                                        ref = \"Nghá»‹_Ä‘á»‹nh\"\n",
    "                                    case \"doc3\":\n",
    "                                        root = metadata[\"law_id\"]\n",
    "                                        ref = \"ThÃ´ng_tÆ°\"\n",
    "                                    case \"doc4\":\n",
    "                                        root = metadata[\"law_id\"]\n",
    "                                        ref = \"Nghá»‹_quyáº¿t\"\n",
    "                                    case \"chapter\":\n",
    "                                        root = chapter_id\n",
    "                                    case \"clause\":\n",
    "                                        root = clause_id\n",
    "                                    case \"point\":\n",
    "                                        root = point_id\n",
    "                                if root is not None:\n",
    "                                    _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "                                else:\n",
    "                                    second_entity = []   \n",
    "                                         \n",
    "                if not second_entity or not relation:\n",
    "                    continue               \n",
    "                for entity in second_entity or []:\n",
    "                    if (list(entity.keys())[0] == None) or list(entity.values())[0] is None:\n",
    "                                        continue\n",
    "                    label = list(entity.keys())[0]       \n",
    "                    ref_type = ref if list(entity.values())[0] == 'Document' else list(entity.values())[0]\n",
    "\n",
    "                    dml_ddl_neo4j(\n",
    "                        f\"\"\"\n",
    "                        MERGE (l:`{ref_type}`:`{ns_label}` {{id: $law_id}})\n",
    "                        WITH l\n",
    "                        MATCH (r:Chapter:`{ns_label}` {{id: $law_id2}})\n",
    "                        MERGE (r)-[:`{relation}`]->(l)\n",
    "                        \"\"\",\n",
    "                        law_id=label,\n",
    "                        law_id2=chapter_id\n",
    "                    )\n",
    "\n",
    "            # Handle Clauses inside the Chapter\n",
    "            for cl in chapter_obj.get(\"clauses\", []):\n",
    "                clause_id = f\"{chapter_id}_C_{cl.get('clause', '?')}\"\n",
    "                clause_text = get_text(cl, \"text\")\n",
    "                root = None\n",
    "                ref = None\n",
    "                second_entity = []\n",
    "\n",
    "                dml_ddl_neo4j(\n",
    "                    f\"\"\"\n",
    "                    MERGE (c:Clause:{ns_label} {{id: $id}})\n",
    "                    SET c.text = $text, c.original_embedding = $embed\n",
    "                    WITH c\n",
    "                    MATCH (ch:Chapter:{ns_label} {{id: $chapter_id}})\n",
    "                    MERGE (ch)-[:HAS_CLAUSE]->(c)\n",
    "                    \"\"\",\n",
    "                    id=clause_id,\n",
    "                    text=clause_text,\n",
    "                    chapter_id=chapter_id,\n",
    "                    embed = text_embedding(clause_text,3,phobert)\n",
    "                )\n",
    "                \n",
    "                #Extract relation\n",
    "                clause_text = re.sub(r'^(ChÆ°Æ¡ng|Äiá»u)\\s*\\d*\\s*', '', clause_text, flags=re.IGNORECASE)\n",
    "                re_text = sent_tokenize(clause_text)\n",
    "                for sentence in re_text:\n",
    "                    root = None\n",
    "                    re_temp = final_re.final_relation(sentence)\n",
    "\n",
    "                    if len(re_temp['document_id']) > 0:\n",
    "                        _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "\n",
    "                    if 'nÃ y' in sentence.split():\n",
    "                        words = sentence.split()\n",
    "                        root = None\n",
    "                        ref = None\n",
    "                        for i, token in enumerate(words):\n",
    "                            if token == \"nÃ y\" and i > 0:\n",
    "                                prev_word = words[i-1]\n",
    "                                if prev_word.lower() in self_check.keys():\n",
    "                                    text_type = self_check[prev_word.lower()]\n",
    "                                    match text_type:\n",
    "                                        case \"doc1\":\n",
    "                                            root = metadata[\"law_id\"]\n",
    "                                            ref = \"Luáº­t\"\n",
    "                                        case \"doc2\":\n",
    "                                            root = metadata[\"law_id\"]\n",
    "                                            ref = \"Nghá»‹_Ä‘á»‹nh\"\n",
    "                                        case \"doc3\":\n",
    "                                            root = metadata[\"law_id\"]\n",
    "                                            ref = \"ThÃ´ng_tÆ°\"\n",
    "                                        case \"doc4\":\n",
    "                                            root = metadata[\"law_id\"]\n",
    "                                            ref = \"Nghá»‹_quyáº¿t\"\n",
    "                                        case \"chapter\":\n",
    "                                            root = chapter_id\n",
    "                                        case \"clause\":\n",
    "                                            root = clause_id\n",
    "                                        case \"point\":\n",
    "                                            root = point_id\n",
    "                                    if root is not None:\n",
    "                                        _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "                                    else:\n",
    "                                        second_entity = []        \n",
    "                    if not second_entity or not relation:\n",
    "                        continue                           \n",
    "                    for entity in second_entity or []:\n",
    "                        if (list(entity.keys())[0] == None) or list(entity.values())[0] is None:\n",
    "                                        continue\n",
    "                        label = list(entity.keys())[0]       \n",
    "                        ref_type = ref if list(entity.values())[0] == 'Document' else list(entity.values())[0]\n",
    "\n",
    "                        dml_ddl_neo4j(\n",
    "                            f\"\"\"\n",
    "                            MERGE (l:`{ref_type}`:`{ns_label}` {{id: $law_id}})\n",
    "                            WITH l\n",
    "                            MATCH (r:Clause:`{ns_label}` {{id: $law_id2}})\n",
    "                            MERGE (r)-[:`{relation}`]->(l)\n",
    "                            \"\"\",\n",
    "                            law_id=label,\n",
    "                            law_id2=clause_id\n",
    "                        )\n",
    "\n",
    "                # Handle Points (1.)\n",
    "                for point in cl.get(\"points\", []):\n",
    "                    point_id = f\"{clause_id}_P_{point.get('point', '?')}\"\n",
    "                    point_text = get_text(point, \"text\")\n",
    "                    root = None\n",
    "                    ref = None\n",
    "                    second_entity = []\n",
    "            \n",
    "                    dml_ddl_neo4j(\n",
    "                        f\"\"\"\n",
    "                        MERGE (p:Point:{ns_label} {{id: $id}})\n",
    "                        SET p.text = $text, p.original_embedding = $embed\n",
    "                        WITH p\n",
    "                        MATCH (c:Clause:{ns_label} {{id: $clause_id}})\n",
    "                        MERGE (c)-[:HAS_POINT]->(p)\n",
    "                        \"\"\",\n",
    "                        id=point_id,\n",
    "                        text=point_text,\n",
    "                        clause_id=clause_id,\n",
    "                        embed = text_embedding(point_text,3,phobert)\n",
    "                    )\n",
    "                    \n",
    "                    #Extract relation\n",
    "                    re_text = sent_tokenize(point_text)\n",
    "                    for sentence in re_text:\n",
    "                        root = None\n",
    "                        re_temp = final_re.final_relation(sentence)\n",
    "\n",
    "                        if len(re_temp['document_id']) > 0:\n",
    "                            _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "\n",
    "                        if 'nÃ y' in sentence.split():\n",
    "                            words = sentence.split()\n",
    "                            root = None\n",
    "                            ref = None\n",
    "                            for i, token in enumerate(words):\n",
    "                                if token == \"nÃ y\" and i > 0:\n",
    "                                    prev_word = words[i-1]\n",
    "                                    if prev_word.lower() in self_check.keys():\n",
    "                                        text_type = self_check[prev_word.lower()]\n",
    "                                        match text_type:\n",
    "                                            case \"doc1\":\n",
    "                                                root = metadata[\"law_id\"]\n",
    "                                                ref = \"Luáº­t\"\n",
    "                                            case \"doc2\":\n",
    "                                                root = metadata[\"law_id\"]\n",
    "                                                ref = \"Nghá»‹_Ä‘á»‹nh\"\n",
    "                                            case \"doc3\":\n",
    "                                                root = metadata[\"law_id\"]\n",
    "                                                ref = \"ThÃ´ng_tÆ°\"\n",
    "                                            case \"doc4\":\n",
    "                                                root = metadata[\"law_id\"]\n",
    "                                                ref = \"Nghá»‹_quyáº¿t\"\n",
    "                                            case \"chapter\":\n",
    "                                                root = chapter_id\n",
    "                                            case \"clause\":\n",
    "                                                root = clause_id\n",
    "                                            case \"point\":\n",
    "                                                root = point_id\n",
    "                                        if root is not None:\n",
    "                                            _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "                                        else:\n",
    "                                            second_entity = []        \n",
    "                        if not second_entity or not relation:\n",
    "                            continue                             \n",
    "                        for entity in second_entity or []:\n",
    "                            if (list(entity.keys())[0] == None) or list(entity.values())[0] is None:\n",
    "                                        continue\n",
    "                            label = list(entity.keys())[0]       \n",
    "                            ref_type = ref if list(entity.values())[0] == 'Document' else list(entity.values())[0]\n",
    "\n",
    "                            dml_ddl_neo4j(\n",
    "                                f\"\"\"\n",
    "                                MERGE (l:`{ref_type}`:`{ns_label}` {{id: $law_id}})\n",
    "                                WITH l\n",
    "                                MATCH (r:Point:`{ns_label}` {{id: $law_id2}})\n",
    "                                MERGE (r)-[:`{relation}`]->(l)\n",
    "                                \"\"\",\n",
    "                                law_id=label,\n",
    "                                law_id2=point_id\n",
    "                            )\n",
    "\n",
    "                    # Handle Subpoints (a))\n",
    "                    for subpoint in point.get(\"subpoints\", []):\n",
    "                        subpoint_id = f\"{point_id}_SP_{subpoint.get('subpoint', '?')}\"\n",
    "                        subpoint_text = get_text(subpoint, \"text\")\n",
    "                        root = None\n",
    "                        ref = None\n",
    "                        second_entity = []\n",
    "                    \n",
    "                        dml_ddl_neo4j(\n",
    "                            f\"\"\"\n",
    "                            MERGE (sp:Subpoint:{ns_label} {{id: $id}})\n",
    "                            SET sp.text = $text, sp.original_embedding = $embed\n",
    "                            WITH sp\n",
    "                            MATCH (p:Point:{ns_label} {{id: $point_id}})\n",
    "                            MERGE (p)-[:HAS_SUBPOINT]->(sp)\n",
    "                            \"\"\",\n",
    "                            id=subpoint_id,\n",
    "                            text=subpoint_text,\n",
    "                            point_id=point_id,\n",
    "                            embed = text_embedding(subpoint_text,3,phobert)\n",
    "                        )\n",
    "                        \n",
    "                        #Extract relation\n",
    "                        re_text = sent_tokenize(subpoint_text)\n",
    "                        for sentence in re_text:\n",
    "                            root = None\n",
    "                            re_temp = final_re.final_relation(sentence)\n",
    "\n",
    "                            if len(re_temp['document_id']) > 0:\n",
    "                                _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "\n",
    "                            if 'nÃ y' in sentence.split():\n",
    "                                words = sentence.split()\n",
    "                                root = None\n",
    "                                ref = None\n",
    "                                for i, token in enumerate(words):\n",
    "                                    if token == \"nÃ y\" and i > 0:\n",
    "                                        prev_word = words[i-1]\n",
    "                                        if prev_word.lower() in self_check.keys():\n",
    "                                            text_type = self_check[prev_word.lower()]\n",
    "                                            match text_type:\n",
    "                                                case \"doc1\":\n",
    "                                                    root = metadata[\"law_id\"]\n",
    "                                                    ref = \"Luáº­t\"\n",
    "                                                case \"doc2\":\n",
    "                                                    root = metadata[\"law_id\"]\n",
    "                                                    ref = \"Nghá»‹_Ä‘á»‹nh\"\n",
    "                                                case \"doc3\":\n",
    "                                                    root = metadata[\"law_id\"]\n",
    "                                                    ref = \"ThÃ´ng_tÆ°\"\n",
    "                                                case \"doc4\":\n",
    "                                                    root = metadata[\"law_id\"]\n",
    "                                                    ref = \"Nghá»‹_quyáº¿t\"\n",
    "                                                case \"chapter\":\n",
    "                                                    root = chapter_id\n",
    "                                                case \"clause\":\n",
    "                                                    root = clause_id\n",
    "                                                case \"point\":\n",
    "                                                    root = point_id\n",
    "                                            if root is not None:\n",
    "                                                _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "                                            else:\n",
    "                                                second_entity = []        \n",
    "                            if not second_entity or not relation:\n",
    "                                continue                              \n",
    "                            for entity in second_entity or []:\n",
    "                                if (list(entity.keys())[0] == None) or list(entity.values())[0] is None:\n",
    "                                        continue\n",
    "                                label = list(entity.keys())[0]       \n",
    "                                ref_type = ref if list(entity.values())[0] == 'Document' else list(entity.values())[0]\n",
    "\n",
    "                                dml_ddl_neo4j(\n",
    "                                    f\"\"\"\n",
    "                                    MERGE (l:`{ref_type}`:`{ns_label}` {{id: $law_id}})\n",
    "                                    WITH l\n",
    "                                    MATCH (r:Subpoint:`{ns_label}` {{id: $law_id2}})\n",
    "                                    MERGE (r)-[:`{relation}`]->(l)\n",
    "                                    \"\"\",\n",
    "                                    law_id=label,\n",
    "                                    law_id2=subpoint_id\n",
    "                                )\n",
    "                            \n",
    "                        # Handle SubSubpoints (a.1))\n",
    "                        for ssp in subpoint.get(\"subsubpoints\", []):\n",
    "                            ssp_id = f\"{subpoint_id}_SSP_{ssp.get('subsubpoint', '?')}\"\n",
    "                            ssp_text = get_text(ssp, \"text\")\n",
    "                            root = None\n",
    "                            ref = None\n",
    "                            second_entity = []\n",
    "                            \n",
    "                            dml_ddl_neo4j(\n",
    "                                f\"\"\"\n",
    "                                MERGE (ssp:Subsubpoint:{ns_label} {{id: $id}})\n",
    "                                SET ssp.text = $text, ssp.original_embedding = $embed\n",
    "                                WITH ssp\n",
    "                                MATCH (sp:Subpoint:{ns_label} {{id: $subpoint_id}})\n",
    "                                MERGE (sp)-[:HAS_SUBSUBPOINT]->(ssp)\n",
    "                                \"\"\",\n",
    "                                id=ssp_id,\n",
    "                                text=ssp_text,\n",
    "                                subpoint_id=subpoint_id,\n",
    "                                embed = text_embedding(ssp_text,3,phobert)\n",
    "                            )\n",
    "                            \n",
    "                            #Extract relation\n",
    "                            re_text = sent_tokenize(ssp_text)\n",
    "                            for sentence in re_text:\n",
    "                                root = None\n",
    "                                re_temp = final_re.final_relation(sentence)\n",
    "\n",
    "                                if len(re_temp['document_id']) > 0:\n",
    "                                    _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "\n",
    "                                if 'nÃ y' in sentence.split():\n",
    "                                    words = sentence.split()\n",
    "                                    root = None\n",
    "                                    ref = None\n",
    "                                    for i, token in enumerate(words):\n",
    "                                        if token == \"nÃ y\" and i > 0:\n",
    "                                            prev_word = words[i-1]\n",
    "                                            if prev_word.lower() in self_check.keys():\n",
    "                                                text_type = self_check[prev_word.lower()]\n",
    "                                                match text_type:\n",
    "                                                    case \"doc1\":\n",
    "                                                        root = metadata[\"law_id\"]\n",
    "                                                        ref = \"Luáº­t\"\n",
    "                                                    case \"doc2\":\n",
    "                                                        root = metadata[\"law_id\"]\n",
    "                                                        ref = \"Nghá»‹_Ä‘á»‹nh\"\n",
    "                                                    case \"doc3\":\n",
    "                                                        root = metadata[\"law_id\"]\n",
    "                                                        ref = \"ThÃ´ng_tÆ°\"\n",
    "                                                    case \"doc4\":\n",
    "                                                        root = metadata[\"law_id\"]\n",
    "                                                        ref = \"Nghá»‹_quyáº¿t\"\n",
    "                                                    case \"chapter\":\n",
    "                                                        root = chapter_id\n",
    "                                                    case \"clause\":\n",
    "                                                        root = clause_id\n",
    "                                                    case \"point\":\n",
    "                                                        root = point_id\n",
    "                                                if root is not None:\n",
    "                                                    _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "                                                else:\n",
    "                                                    second_entity = []        \n",
    "                                if not second_entity or not relation:\n",
    "                                    continue                               \n",
    "                                for entity in second_entity or []:\n",
    "                                    if (list(entity.keys())[0] == None) or list(entity.values())[0] is None:\n",
    "                                        continue\n",
    "                                    label = list(entity.keys())[0]       \n",
    "                                    ref_type = ref if list(entity.values())[0] == 'Document' else list(entity.values())[0]\n",
    "\n",
    "                                    dml_ddl_neo4j(\n",
    "                                        f\"\"\"\n",
    "                                        MERGE (l:`{ref_type}`:`{ns_label}` {{id: $law_id}})\n",
    "                                        WITH l\n",
    "                                        MATCH (r:Subsubpoint:`{ns_label}` {{id: $law_id2}})\n",
    "                                        MERGE (r)-[:`{relation}`]->(l)\n",
    "                                        \"\"\",\n",
    "                                        law_id=label,\n",
    "                                        law_id2=ssp_id\n",
    "                                    )\n",
    "\n",
    "                            # Handle SubSubSubpoints (a.1.1))\n",
    "                            for sssp in ssp.get(\"subsubsubpoints\", []):\n",
    "                                sssp_id = f\"{ssp_id}_SSSP_{sssp.get('subsubsubpoint', '?')}\"\n",
    "                                sssp_text = get_text(sssp, \"text\")\n",
    "                                root = None\n",
    "                                ref = None\n",
    "                                second_entity = []\n",
    "                                \n",
    "                                dml_ddl_neo4j(\n",
    "                                    f\"\"\"\n",
    "                                    MERGE (sssp:Subsubsubpoint:{ns_label} {{id: $id}})\n",
    "                                    SET sssp.text = $text, sssp.original_embedding = $embed\n",
    "                                    WITH sssp\n",
    "                                    MATCH (ssp:Subsubpoint:{ns_label} {{id: $ssp_id}})\n",
    "                                    MERGE (ssp)-[:HAS_SUBSUBSUBPOINT]->(sssp)\n",
    "                                    \"\"\",\n",
    "                                    id=sssp_id,\n",
    "                                    text=sssp_text,\n",
    "                                    ssp_id=ssp_id,\n",
    "                                    embed = text_embedding(sssp_text,3,phobert)\n",
    "                                )\n",
    "                                \n",
    "                                #Extract relation\n",
    "                                re_text = sent_tokenize(sssp_text)\n",
    "                                for sentence in re_text:\n",
    "                                    root = None\n",
    "                                    re_temp = final_re.final_relation(sentence)\n",
    "\n",
    "                                    if len(re_temp['document_id']) > 0:\n",
    "                                        _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "\n",
    "                                    if 'nÃ y' in sentence.split():\n",
    "                                        words = sentence.split()\n",
    "                                        root = None\n",
    "                                        ref = None\n",
    "                                        for i, token in enumerate(words):\n",
    "                                            if token == \"nÃ y\" and i > 0:\n",
    "                                                prev_word = words[i-1]\n",
    "                                                if prev_word.lower() in self_check.keys():\n",
    "                                                    text_type = self_check[prev_word.lower()]\n",
    "                                                    match text_type:\n",
    "                                                        case \"doc1\":\n",
    "                                                            root = metadata[\"law_id\"]\n",
    "                                                            ref = \"Luáº­t\"\n",
    "                                                        case \"doc2\":\n",
    "                                                            root = metadata[\"law_id\"]\n",
    "                                                            ref = \"Nghá»‹_Ä‘á»‹nh\"\n",
    "                                                        case \"doc3\":\n",
    "                                                            root = metadata[\"law_id\"]\n",
    "                                                            ref = \"ThÃ´ng_tÆ°\"\n",
    "                                                        case \"doc4\":\n",
    "                                                            root = metadata[\"law_id\"]\n",
    "                                                            ref = \"Nghá»‹_quyáº¿t\"\n",
    "                                                        case \"chapter\":\n",
    "                                                            root = chapter_id\n",
    "                                                        case \"clause\":\n",
    "                                                            root = clause_id\n",
    "                                                        case \"point\":\n",
    "                                                            root = point_id\n",
    "                                                    if root is not None:\n",
    "                                                        _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "                                                    else:\n",
    "                                                        second_entity = []        \n",
    "                                    if not second_entity or not relation:\n",
    "                                        continue                                \n",
    "                                    for entity in second_entity or []:\n",
    "                                        if (list(entity.keys())[0] == None) or list(entity.values())[0] is None:\n",
    "                                            continue\n",
    "                                        label = list(entity.keys())[0]       \n",
    "                                        ref_type = ref if list(entity.values())[0] == 'Document' else list(entity.values())[0]\n",
    "\n",
    "                                        dml_ddl_neo4j(\n",
    "                                            f\"\"\"\n",
    "                                            MERGE (l:`{ref_type}`:`{ns_label}` {{id: $law_id}})\n",
    "                                            WITH l\n",
    "                                            MATCH (r:Subsubsubpoint:`{ns_label}` {{id: $law_id2}})\n",
    "                                            MERGE (r)-[:`{relation}`]->(l)\n",
    "                                            \"\"\",\n",
    "                                            law_id=label,\n",
    "                                            law_id2=sssp_id\n",
    "                                        )\n",
    "\n",
    "    # If WITHOUT chapters (only clauses)\n",
    "    elif \"clauses\" in parsed:\n",
    "        for cl in parsed[\"clauses\"]:\n",
    "            clause_id = f\"{metadata['law_id']}_C_{cl.get('clause', '?')}\"\n",
    "            clause_text = get_text(cl, \"text\")\n",
    "            re_text = None\n",
    "            re_temp = None\n",
    "            relation = None\n",
    "            second_entity = []\n",
    "            \n",
    "            dml_ddl_neo4j(\n",
    "                f\"\"\"\n",
    "                MERGE (c:Clause:{ns_label} {{id: $id}})\n",
    "                SET c.text = $text, c.original_embedding = $embed\n",
    "                WITH c\n",
    "                MATCH (l:{ns_label} {{id: $law_id}})\n",
    "                MERGE (l)-[:HAS_CLAUSE]->(c)\n",
    "                \"\"\",\n",
    "                id=clause_id,\n",
    "                text=clause_text,\n",
    "                law_id=metadata[\"law_id\"],\n",
    "                embed = text_embedding(clause_text,3,phobert)\n",
    "            )\n",
    "\n",
    "            #Extract relation\n",
    "            clause_text = re.sub(r'^(ChÆ°Æ¡ng|Äiá»u)\\s*\\d*\\s*', '', clause_text, flags=re.IGNORECASE)\n",
    "            re_text = sent_tokenize(clause_text)\n",
    "            for sentence in re_text:\n",
    "                root = None\n",
    "                re_temp = final_re.final_relation(sentence)\n",
    "\n",
    "                if len(re_temp['document_id']) > 0:\n",
    "                    _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "\n",
    "                if 'nÃ y' in sentence.split():\n",
    "                    words = sentence.split()\n",
    "                    root = None\n",
    "                    ref = None\n",
    "                    for i, token in enumerate(words):\n",
    "                        if token == \"nÃ y\" and i > 0:\n",
    "                            prev_word = words[i-1]\n",
    "                            if prev_word.lower() in self_check.keys():\n",
    "                                text_type = self_check[prev_word.lower()]\n",
    "                                match text_type:\n",
    "                                    case \"doc1\":\n",
    "                                        root = metadata[\"law_id\"]\n",
    "                                        ref = \"Luáº­t\"\n",
    "                                    case \"doc2\":\n",
    "                                        root = metadata[\"law_id\"]\n",
    "                                        ref = \"Nghá»‹_Ä‘á»‹nh\"\n",
    "                                    case \"doc3\":\n",
    "                                        root = metadata[\"law_id\"]\n",
    "                                        ref = \"ThÃ´ng_tÆ°\"\n",
    "                                    case \"doc4\":\n",
    "                                        root = metadata[\"law_id\"]\n",
    "                                        ref = \"Nghá»‹_quyáº¿t\"\n",
    "                                    case \"chapter\":\n",
    "                                        root = chapter_id\n",
    "                                    case \"clause\":\n",
    "                                        root = clause_id\n",
    "                                    case \"point\":\n",
    "                                        root = point_id\n",
    "                                if root is not None:\n",
    "                                    _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "                                else:\n",
    "                                    second_entity = []        \n",
    "                if not second_entity or not relation:\n",
    "                    continue                                \n",
    "                for entity in second_entity or []:\n",
    "                    if (list(entity.keys())[0] == None) or list(entity.values())[0] is None:\n",
    "                        continue\n",
    "                    label = list(entity.keys())[0]       \n",
    "                    ref_type = ref if list(entity.values())[0] == 'Document' else list(entity.values())[0]\n",
    "\n",
    "                    dml_ddl_neo4j(\n",
    "                        f\"\"\"\n",
    "                        MERGE (l:`{ref_type}`:`{ns_label}` {{id: $law_id}})\n",
    "                        WITH l\n",
    "                        MATCH (r:Clause:`{ns_label}` {{id: $law_id2}})\n",
    "                        MERGE (r)-[:`{relation}`]->(l)\n",
    "                        \"\"\",\n",
    "                        law_id=label,\n",
    "                        law_id2=clause_id\n",
    "                    )\n",
    "                \n",
    "            #Handle Point\n",
    "            for point in cl.get(\"points\", []):\n",
    "                point_id = f\"{clause_id}_P_{point.get('point', '?')}\"\n",
    "                point_text = get_text(point, \"text\")\n",
    "                \n",
    "                root = None\n",
    "                ref = None\n",
    "                second_entity = []\n",
    "\n",
    "                dml_ddl_neo4j(\n",
    "                    f\"\"\"\n",
    "                    MERGE (p:Point:{ns_label} {{id: $id}})\n",
    "                    SET p.text = $text, p.original_embedding = $embed\n",
    "                    WITH p\n",
    "                    MATCH (c:Clause:{ns_label} {{id: $clause_id}})\n",
    "                    MERGE (c)-[:HAS_POINT]->(p)\n",
    "                    \"\"\",\n",
    "                    id=point_id,\n",
    "                    text=point_text,\n",
    "                    clause_id=clause_id,\n",
    "                    embed = text_embedding(point_text,3,phobert)\n",
    "                )\n",
    "                \n",
    "                #Extract relation\n",
    "                re_text = sent_tokenize(point_text)\n",
    "                for sentence in re_text:\n",
    "                    root = None\n",
    "                    re_temp = final_re.final_relation(sentence)\n",
    "\n",
    "                    if len(re_temp['document_id']) > 0:\n",
    "                        _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "\n",
    "                    if 'nÃ y' in sentence.split():\n",
    "                        words = sentence.split()\n",
    "                        root = None\n",
    "                        ref = None\n",
    "                        for i, token in enumerate(words):\n",
    "                            if token == \"nÃ y\" and i > 0:\n",
    "                                prev_word = words[i-1]\n",
    "                                if prev_word.lower() in self_check.keys():\n",
    "                                    text_type = self_check[prev_word.lower()]\n",
    "                                    match text_type:\n",
    "                                        case \"doc1\":\n",
    "                                            root = metadata[\"law_id\"]\n",
    "                                            ref = \"Luáº­t\"\n",
    "                                        case \"doc2\":\n",
    "                                            root = metadata[\"law_id\"]\n",
    "                                            ref = \"Nghá»‹_Ä‘á»‹nh\"\n",
    "                                        case \"doc3\":\n",
    "                                            root = metadata[\"law_id\"]\n",
    "                                            ref = \"ThÃ´ng_tÆ°\"\n",
    "                                        case \"doc4\":\n",
    "                                            root = metadata[\"law_id\"]\n",
    "                                            ref = \"Nghá»‹_quyáº¿t\"\n",
    "                                        case \"chapter\":\n",
    "                                            root = chapter_id\n",
    "                                        case \"clause\":\n",
    "                                            root = clause_id\n",
    "                                        case \"point\":\n",
    "                                            root = point_id\n",
    "                                    if root is not None:\n",
    "                                        _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "                                    else:\n",
    "                                        second_entity = []        \n",
    "                    if not second_entity or not relation:\n",
    "                        continue                               \n",
    "                    for entity in second_entity or []:\n",
    "                        if (list(entity.keys())[0] == None) or list(entity.values())[0] is None:\n",
    "                            continue\n",
    "                        label = list(entity.keys())[0]       \n",
    "                        ref_type = ref if list(entity.values())[0] == 'Document' else list(entity.values())[0]\n",
    "\n",
    "                        dml_ddl_neo4j(\n",
    "                            f\"\"\"\n",
    "                            MERGE (l:`{ref_type}`:`{ns_label}` {{id: $law_id}})\n",
    "                            WITH l\n",
    "                            MATCH (r:Point:`{ns_label}` {{id: $law_id2}})\n",
    "                            MERGE (r)-[:`{relation}`]->(l)\n",
    "                            \"\"\",\n",
    "                            law_id=label,\n",
    "                            law_id2=point_id\n",
    "                        )\n",
    "                \n",
    "                #Handle Subpoint\n",
    "                for subpoint in point.get(\"subpoints\", []):\n",
    "                    subpoint_id = f\"{point_id}_SP_{subpoint.get('subpoint', '?')}\"\n",
    "                    subpoint_text = get_text(subpoint, \"text\")\n",
    "                    \n",
    "                    root = None\n",
    "                    ref = None\n",
    "                    second_entity = []\n",
    "                    \n",
    "                    dml_ddl_neo4j(\n",
    "                        f\"\"\"\n",
    "                        MERGE (sp:Subpoint:{ns_label} {{id: $id}})\n",
    "                        SET sp.text = $text, sp.original_embedding = $embed\n",
    "                        WITH sp\n",
    "                        MATCH (p:Point:{ns_label} {{id: $point_id}})\n",
    "                        MERGE (p)-[:HAS_SUBPOINT]->(sp)\n",
    "                        \"\"\",\n",
    "                        id=subpoint_id,\n",
    "                        text=subpoint_text,\n",
    "                        point_id=point_id,\n",
    "                        embed = text_embedding(subpoint_text,3,phobert)\n",
    "                    )\n",
    "                    \n",
    "                    #Extract relation\n",
    "                    re_text = sent_tokenize(subpoint_text)\n",
    "                    for sentence in re_text:\n",
    "                        root = None\n",
    "                        re_temp = final_re.final_relation(sentence)\n",
    "\n",
    "                        if len(re_temp['document_id']) > 0:\n",
    "                            _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "\n",
    "                        if 'nÃ y' in sentence.split():\n",
    "                            words = sentence.split()\n",
    "                            root = None\n",
    "                            ref = None\n",
    "                            for i, token in enumerate(words):\n",
    "                                if token == \"nÃ y\" and i > 0:\n",
    "                                    prev_word = words[i-1]\n",
    "                                    if prev_word.lower() in self_check.keys():\n",
    "                                        text_type = self_check[prev_word.lower()]\n",
    "                                        match text_type:\n",
    "                                            case \"doc1\":\n",
    "                                                root = metadata[\"law_id\"]\n",
    "                                                ref = \"Luáº­t\"\n",
    "                                            case \"doc2\":\n",
    "                                                root = metadata[\"law_id\"]\n",
    "                                                ref = \"Nghá»‹_Ä‘á»‹nh\"\n",
    "                                            case \"doc3\":\n",
    "                                                root = metadata[\"law_id\"]\n",
    "                                                ref = \"ThÃ´ng_tÆ°\"\n",
    "                                            case \"doc4\":\n",
    "                                                root = metadata[\"law_id\"]\n",
    "                                                ref = \"Nghá»‹_quyáº¿t\"\n",
    "                                            case \"chapter\":\n",
    "                                                root = chapter_id\n",
    "                                            case \"clause\":\n",
    "                                                root = clause_id\n",
    "                                            case \"point\":\n",
    "                                                root = point_id\n",
    "                                        if root is not None:\n",
    "                                            _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "                                        else:\n",
    "                                            second_entity = []        \n",
    "                        if not second_entity or not relation:\n",
    "                                    continue                            \n",
    "                        for entity in second_entity or []:\n",
    "                            if (list(entity.keys())[0] == None) or list(entity.values())[0] is None:\n",
    "                                continue\n",
    "                            label = list(entity.keys())[0]       \n",
    "                            ref_type = ref if list(entity.values())[0] == 'Document' else list(entity.values())[0]\n",
    "\n",
    "                            dml_ddl_neo4j(\n",
    "                                f\"\"\"\n",
    "                                MERGE (l:`{ref_type}`:`{ns_label}` {{id: $law_id}})\n",
    "                                WITH l\n",
    "                                MATCH (r:Subpoint:`{ns_label}` {{id: $law_id2}})\n",
    "                                MERGE (r)-[:`{relation}`]->(l)\n",
    "                                \"\"\",\n",
    "                                law_id=label,\n",
    "                                law_id2=subpoint_id\n",
    "                            )\n",
    "                    \n",
    "                    # Handle SubSubpoints (a.1))\n",
    "                    for ssp in subpoint.get(\"subsubpoints\", []):\n",
    "                        ssp_id = f\"{subpoint_id}_SSP_{ssp.get('subsubpoint', '?')}\"\n",
    "                        ssp_text = get_text(ssp, \"text\")\n",
    "                        \n",
    "                        root = None\n",
    "                        ref = None\n",
    "                        second_entity = []\n",
    "\n",
    "                        dml_ddl_neo4j(\n",
    "                            f\"\"\"\n",
    "                            MERGE (ssp:Subsubpoint:{ns_label} {{id: $id}})\n",
    "                            SET ssp.text = $text, ssp.original_embedding = $embed\n",
    "                            WITH ssp\n",
    "                            MATCH (sp:Subpoint:{ns_label} {{id: $subpoint_id}})\n",
    "                            MERGE (sp)-[:HAS_SUBSUBPOINT]->(ssp)\n",
    "                            \"\"\",\n",
    "                            id=ssp_id,\n",
    "                            text=ssp_text,\n",
    "                            subpoint_id=subpoint_id,\n",
    "                            embed = text_embedding(ssp_text,3,phobert)\n",
    "                        )\n",
    "                        \n",
    "                        #Extract relation\n",
    "                        re_text = sent_tokenize(ssp_text)\n",
    "                        for sentence in re_text:\n",
    "                            root = None\n",
    "                            re_temp = final_re.final_relation(sentence)\n",
    "\n",
    "                            if len(re_temp['document_id']) > 0:\n",
    "                                _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "\n",
    "                            if 'nÃ y' in sentence.split():\n",
    "                                words = sentence.split()\n",
    "                                root = None\n",
    "                                ref = None\n",
    "                                for i, token in enumerate(words):\n",
    "                                    if token == \"nÃ y\" and i > 0:\n",
    "                                        prev_word = words[i-1]\n",
    "                                        if prev_word.lower() in self_check.keys():\n",
    "                                            text_type = self_check[prev_word.lower()]\n",
    "                                            match text_type:\n",
    "                                                case \"doc1\":\n",
    "                                                    root = metadata[\"law_id\"]\n",
    "                                                    ref = \"Luáº­t\"\n",
    "                                                case \"doc2\":\n",
    "                                                    root = metadata[\"law_id\"]\n",
    "                                                    ref = \"Nghá»‹_Ä‘á»‹nh\"\n",
    "                                                case \"doc3\":\n",
    "                                                    root = metadata[\"law_id\"]\n",
    "                                                    ref = \"ThÃ´ng_tÆ°\"\n",
    "                                                case \"doc4\":\n",
    "                                                    root = metadata[\"law_id\"]\n",
    "                                                    ref = \"Nghá»‹_quyáº¿t\"\n",
    "                                                case \"chapter\":\n",
    "                                                    root = chapter_id\n",
    "                                                case \"clause\":\n",
    "                                                    root = clause_id\n",
    "                                                case \"point\":\n",
    "                                                    root = point_id\n",
    "                                            if root is not None:\n",
    "                                                _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "                                            else:\n",
    "                                                second_entity = []        \n",
    "                            if not second_entity or not relation:\n",
    "                                    continue                              \n",
    "                            for entity in second_entity or []:\n",
    "                                if (list(entity.keys())[0] == None) or list(entity.values())[0] is None:\n",
    "                                    continue\n",
    "                                label = list(entity.keys())[0]       \n",
    "                                ref_type = ref if list(entity.values())[0] == 'Document' else list(entity.values())[0]\n",
    "                                \n",
    "                                dml_ddl_neo4j(\n",
    "                                    f\"\"\"\n",
    "                                    MERGE (l:`{ref_type}`:`{ns_label}` {{id: $law_id}})\n",
    "                                    WITH l\n",
    "                                    MATCH (r:Subsubpoint:`{ns_label}` {{id: $law_id2}})\n",
    "                                    MERGE (r)-[:`{relation}`]->(l)\n",
    "                                    \"\"\",\n",
    "                                    law_id=label,\n",
    "                                    law_id2=ssp_id\n",
    "                                )\n",
    "\n",
    "                        # Handle SubSubSubpoints (a.1.1))\n",
    "                        for sssp in ssp.get(\"subsubsubpoints\", []):\n",
    "                            sssp_id = f\"{ssp_id}_SSSP_{sssp.get('subsubsubpoint', '?')}\"\n",
    "                            sssp_text = get_text(sssp, \"text\")\n",
    "                            \n",
    "                            root = None\n",
    "                            ref = None\n",
    "                            second_entity = []\n",
    "\n",
    "                            dml_ddl_neo4j(\n",
    "                                f\"\"\"\n",
    "                                MERGE (sssp:Subsubsubpoint:{ns_label} {{id: $id}})\n",
    "                                SET sssp.text = $text, sssp.original_embedding = $embed\n",
    "                                WITH sssp\n",
    "                                MATCH (ssp:Subsubpoint:{ns_label} {{id: $ssp_id}})\n",
    "                                MERGE (ssp)-[:HAS_SUBSUBSUBPOINT]->(sssp)\n",
    "                                \"\"\",\n",
    "                                id=sssp_id,\n",
    "                                text=sssp_text,\n",
    "                                ssp_id=ssp_id,\n",
    "                                embed = text_embedding(sssp_text, 3, phobert)\n",
    "                            )\n",
    "                            \n",
    "                            #Extract relation\n",
    "                            re_text = sent_tokenize(sssp_text)\n",
    "                            for sentence in re_text:\n",
    "                                root = None\n",
    "                                re_temp = final_re.final_relation(sentence)\n",
    "\n",
    "                                if len(re_temp['document_id']) > 0:\n",
    "                                    _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "\n",
    "                                if 'nÃ y' in sentence.split():\n",
    "                                    words = sentence.split()\n",
    "                                    root = None\n",
    "                                    ref = None\n",
    "                                    for i, token in enumerate(words):\n",
    "                                        if token == \"nÃ y\" and i > 0:\n",
    "                                            prev_word = words[i-1]\n",
    "                                            if prev_word.lower() in self_check.keys():\n",
    "                                                text_type = self_check[prev_word.lower()]\n",
    "                                                match text_type:\n",
    "                                                    case \"doc1\":\n",
    "                                                        root = metadata[\"law_id\"]\n",
    "                                                        ref = \"Luáº­t\"\n",
    "                                                    case \"doc2\":\n",
    "                                                        root = metadata[\"law_id\"]\n",
    "                                                        ref = \"Nghá»‹_Ä‘á»‹nh\"\n",
    "                                                    case \"doc3\":\n",
    "                                                        root = metadata[\"law_id\"]\n",
    "                                                        ref = \"ThÃ´ng_tÆ°\"\n",
    "                                                    case \"doc4\":\n",
    "                                                        root = metadata[\"law_id\"]\n",
    "                                                        ref = \"Nghá»‹_quyáº¿t\"\n",
    "                                                    case \"chapter\":\n",
    "                                                        root = chapter_id\n",
    "                                                    case \"clause\":\n",
    "                                                        root = clause_id\n",
    "                                                    case \"point\":\n",
    "                                                        root = point_id\n",
    "                                                if root is not None:\n",
    "                                                    _, relation, second_entity = final_re.extract_relation_entities(sentence, root)\n",
    "                                                else:\n",
    "                                                    second_entity = []        \n",
    "                                if not second_entity or not relation:\n",
    "                                    continue                          \n",
    "                                for entity in second_entity or []:\n",
    "                                    if (list(entity.keys())[0] == None) or list(entity.values())[0] is None:\n",
    "                                        continue\n",
    "                                    label = list(entity.keys())[0]       \n",
    "                                    ref_type = ref if list(entity.values())[0] == \"Document\" else list(entity.values())[0] \n",
    "\n",
    "                                    dml_ddl_neo4j(\n",
    "                                        f\"\"\"\n",
    "                                        MERGE (l:`{ref_type}`:`{ns_label}` {{id: $law_id}})\n",
    "                                        WITH l\n",
    "                                        MATCH (r:Subsubsubpoint:`{ns_label}` {{id: $law_id2}})\n",
    "                                        MERGE (r)-[:`{relation}`]->(l)\n",
    "                                        \"\"\",\n",
    "                                        law_id=label,\n",
    "                                        law_id2=sssp_id\n",
    "                                    )\n",
    "\n",
    "    # Cleanup temporary \"no_chapter\" node\n",
    "    dml_ddl_neo4j(\n",
    "        f\"\"\"\n",
    "        MATCH (ch:Chapter:{ns_label})\n",
    "        WHERE ch.id ENDS WITH \"_no_chapter\"\n",
    "        DETACH DELETE ch\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    dml_ddl_neo4j(\n",
    "            f'''\n",
    "            MATCH (n:{ns_label})\n",
    "            WHERE n.id =~ '(?i)^[aeiou].*'\n",
    "            DETACH DELETE n\n",
    "            '''\n",
    "        )\n",
    "    \n",
    "    dml_ddl_neo4j(\n",
    "            f'''\n",
    "            MATCH (n:{ns_label})\n",
    "            WITH n, size(keys(n)) AS propCount\n",
    "            WHERE propCount < 3\n",
    "            DETACH DELETE n;\n",
    "\n",
    "            '''\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0c805a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”œâ”€â”€ Luáº­t\n",
      "â”‚   â”œâ”€â”€ luat_16_2023_QH15_519324.pdf\n",
      "â”‚   â”œâ”€â”€ luat_22_2023_QH15_518805.pdf\n",
      "â”‚   â”œâ”€â”€ luat_31_2024_QH15_523642.pdf\n",
      "â”‚   â”œâ”€â”€ luat_33_2024_QH15_545181.pdf\n",
      "â”‚   â”œâ”€â”€ luat_38_2019_QH14_387595.pdf\n",
      "â”‚   â”œâ”€â”€ luat_39_2024_QH15_575158.pdf\n",
      "â”‚   â”œâ”€â”€ luat_46_2024_QH15_524982.pdf\n",
      "â”‚   â”œâ”€â”€ luat_48_2024_QH15_556390.pdf\n",
      "â”‚   â”œâ”€â”€ luat_50_2024_QH15_445264.pdf\n",
      "â”‚   â”œâ”€â”€ luat_60_2024_QH15_621343.pdf\n",
      "â”‚   â”œâ”€â”€ luat_61_2024_QH15_613892.pdf\n",
      "â”‚   â”œâ”€â”€ luat_66_2025_QH15_621225.pdf\n",
      "â”‚   â”œâ”€â”€ luat_67_2025_QH15_580594.pdf\n",
      "â”‚   â”œâ”€â”€ luat_90_2025_QH15_662379.pdf\n",
      "â”‚   â””â”€â”€ luat_97_2015_QH13_298376.pdf\n",
      "â”œâ”€â”€ Nghá»‹ Quyáº¿t\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_01_2020_NQ-HDND_448623.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_01_2025_NQ-HDND_642122.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_01_2025_NQ-HDND_666755.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_02_2025_NQ-HDND_650773.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_04_2025_NQ-HDND_662868.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_04_2025_NQ-HDND_676671.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_05_2025_NQ-HDND_667873.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_05_2025_NQ-HDND_675524.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_05_2025_NQ-HDND_676654.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_06_2025_NQ-HDND_659674.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_08_2023_NQ-HDND_574278.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_08_2025_NQ-HDND_655056.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_101_2023_NQ-HDND_573789.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_115_2025_NQ-HDND_665545.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_11_2025_NQ-HDND_661184.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_11_2025_NQ-HDND_666220.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_12_2025_NQ-HDND_663392.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_12_2025_NQ-HDND_679979.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_156_2025_NQ-HDND_668781.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_15_2025_NQ-HDND_678933.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_15_2025_NQ-HDND_681351.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_16_2023_NQ-HDND_662371.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_18_2025_NQ-HDND_665548.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_18_2025_NQ-HDND_674753.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_19_2025_NQ-HDND_672412.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_1_2025_NQ-HDND_667328.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_20_2024_NQ-HDND_631963.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_22_2024_NQ-HDND_635804.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_24_2024_NQ-HDND_635888.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_28_2020_NQ-HDND_447834.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_32_2025_NQ-HDND_680594.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_67_2025_NQ-HDND_675675.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_quyet_97_2025_NQ-HDND_664184.pdf\n",
      "â”‚   â””â”€â”€ nghi_quyet_giam_VAT_2024.pdf\n",
      "â”œâ”€â”€ Nghá»‹ Äá»‹nh\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_102_2021_ND-CP_494746.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_103_2024_ND-CP_550020.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_10_2021_ND-CP_465104.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_10_2022_ND-CP_484768.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_10_2025_ND-CP_557471.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_114_2016_ND-CP_317584.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_11_2024_ND-CP_598025.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_120_2016_ND-CP_320506.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_122_2025_ND-CP_660465.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_123_2017_ND-CP_367263.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_125_2020_ND-CP_455646.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_126_2020_ND-CP_455733.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_12_2023_ND-CP_563407.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_130_2024_ND-CP_621998.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_132_2020_ND-CP_452218.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_134_2016_ND-CP_323602.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_139_2016_ND-CP_315033.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_140_2016_ND-CP_325345.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_153_2024_ND-CP_575467.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_154_2016_ND-CP_330069.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_164_2016_ND-CP_325915.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_174_2025_ND-CP_663151.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_176_2024_ND-CP_637930.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_17_2025_ND-CP_632484.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_180_2024_ND-CP_634111.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_181_2025_ND-CP_646124.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_204_2025_ND-CP_664702.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_225_2025_ND-CP_669512.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_226_2025_ND-CP_664033.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_236_2025_ND-CP_631519.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_238_2025_ND-CP_662922.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_26_2023_ND-CP_548616.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_27_2023_ND-CP_568198.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_286_2025_ND-CP_679657.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_32_2015_ND-CP_269169.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_34_2022_ND-CP_510087.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_41_2020_ND-CP_438649.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_44_2021_ND-CP_463357.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_44_2023_ND-CP_569851.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_50_2025_ND-CP_633449.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_52_2021_ND-CP_471423.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_53_2011_ND-CP_126042.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_53_2020_ND-CP_411948.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_64_2024_ND-CP_609734.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_68_2019_ND-CP_421141.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_71_2024_ND-CP_599145.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_72_2024_ND-CP_611445.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_73_2025_ND-CP_649748.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_81_2021_ND-CP_457392.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_82_2025_ND-CP_643688.pdf\n",
      "â”‚   â”œâ”€â”€ nghi_dinh_90_2023_ND-CP_591410.pdf\n",
      "â”‚   â””â”€â”€ nghi_dinh_94_2023_ND-CP_589156.pdf\n",
      "â”œâ”€â”€ Quyáº¿t Äá»‹nh\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_1034_QD-BTC_649081.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_1377_QD-CT_664418.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_15_QD-CT_646296.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_20_2024_QD-UBND_615244.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_2113_QD-BTC_662417.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_2138_QD-BTC_663660.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_2167_QD-UBND_664657.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_2368_QD-BTC_608811.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_3057_QD-UBND_674648.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_308_QD-CT_648658.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_322_QD-UBND_658718.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_3509_QD-CT_681517.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_36_2022_QD-UBND_528967.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_372_QD-BTC_659599.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_3734_QD-BCT_638325.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_37_2023_QD-UBND_575153.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_386_QD-TCT_639111.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_43_2025_QD-UBND_673325.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_4663_QD-KBNN_491762.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_496_QD-TCT_608275.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_50_2025_QD-UBND_662090.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_559_QD-UBND_677965.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_66_2025_QD-UBND_653709.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_75_2024_QD-UBND_632504.pdf\n",
      "â”‚   â”œâ”€â”€ quyet_dinh_85_2023_QD-UBND_591864.pdf\n",
      "â”‚   â””â”€â”€ quyet_dinh_929_QD-KBNN_646996.pdf\n",
      "â””â”€â”€ ThÃ´ng TÆ°\n",
      "    â”œâ”€â”€ thong_tu_01_2016_TT-BTC_299832.pdf\n",
      "    â”œâ”€â”€ thong_tu_04_2020_TT-BTTTT_435371.pdf\n",
      "    â”œâ”€â”€ thong_tu_05_2024_TT-BKHDT_607705.pdf\n",
      "    â”œâ”€â”€ thong_tu_08_2024_TT-BTC_598445.pdf\n",
      "    â”œâ”€â”€ thong_tu_101_2020_TT-BTC_460266.pdf\n",
      "    â”œâ”€â”€ thong_tu_109_2025_TT-BTC_681406.pdf\n",
      "    â”œâ”€â”€ thong_tu_10_2024_TT-BTC_598448.pdf\n",
      "    â”œâ”€â”€ thong_tu_10_2025_TT-BTC_648167.pdf\n",
      "    â”œâ”€â”€ thong_tu_110_2025_TT-BTC_681515.pdf\n",
      "    â”œâ”€â”€ thong_tu_11_2021_TT-BXD_427310.pdf\n",
      "    â”œâ”€â”€ thong_tu_12_2020_TT-BTTTT_443848.pdf\n",
      "    â”œâ”€â”€ thong_tu_13_2025_TT-BTC_648172.pdf\n",
      "    â”œâ”€â”€ thong_tu_14_2023_TT-NHNN_555121.pdf\n",
      "    â”œâ”€â”€ thong_tu_15_2025_TT-BTC_652307.pdf\n",
      "    â”œâ”€â”€ thong_tu_16_2025_TT-BTC_654125.pdf\n",
      "    â”œâ”€â”€ thong_tu_16_2025_TT-BTP_674352.pdf\n",
      "    â”œâ”€â”€ thong_tu_17_2025_TT-BXD_663708.pdf\n",
      "    â”œâ”€â”€ thong_tu_18_2024_TT-BTTTT_638147.pdf\n",
      "    â”œâ”€â”€ thong_tu_20_2024_TT-BTP_632486.pdf\n",
      "    â”œâ”€â”€ thong_tu_20_2025_TT-NHNN_668163.pdf\n",
      "    â”œâ”€â”€ thong_tu_21_2025_TT-BXD_666462.pdf\n",
      "    â”œâ”€â”€ thong_tu_261_2016_TT-BTC_319384.pdf\n",
      "    â”œâ”€â”€ thong_tu_27_2023_TT-BTC_567023.pdf\n",
      "    â”œâ”€â”€ thong_tu_29_2021_TT-BTC_473094.pdf\n",
      "    â”œâ”€â”€ thong_tu_31_2022_TT-BGTVT_545115.pdf\n",
      "    â”œâ”€â”€ thong_tu_34_2020_TT-BTC_441696.pdf\n",
      "    â”œâ”€â”€ thong_tu_34_2024_TT-BGTVT_622720.pdf\n",
      "    â”œâ”€â”€ thong_tu_35_2024_TT-NHNN_616727.pdf\n",
      "    â”œâ”€â”€ thong_tu_37_2020_TT-BTC_441845.pdf\n",
      "    â”œâ”€â”€ thong_tu_37_2021_TT-BGTVT_499555.pdf\n",
      "    â”œâ”€â”€ thong_tu_37_2023_TT-BTC_550018.pdf\n",
      "    â”œâ”€â”€ thong_tu_42_2024_TT-BGTVT_638530.pdf\n",
      "    â”œâ”€â”€ thong_tu_43_2024_TT-BTC_611296.pdf\n",
      "    â”œâ”€â”€ thong_tu_44_2023_TT-BTC_571310.pdf\n",
      "    â”œâ”€â”€ thong_tu_45_2021_TT-BGTVT_502706.pdf\n",
      "    â”œâ”€â”€ thong_tu_46_2020_TT-BTC_443793.pdf\n",
      "    â”œâ”€â”€ thong_tu_52_2024_TT-BTC_619230.pdf\n",
      "    â”œâ”€â”€ thong_tu_52_2025_TT-BTC_662964.pdf\n",
      "    â”œâ”€â”€ thong_tu_55_2025_TT-BTC_663222.pdf\n",
      "    â”œâ”€â”€ thong_tu_56_2020_TT-BTC_444816.pdf\n",
      "    â”œâ”€â”€ thong_tu_56_2024_TT-BTC_619772.pdf\n",
      "    â”œâ”€â”€ thong_tu_57_2024_TT-NHNN_638049.pdf\n",
      "    â”œâ”€â”€ thong_tu_58_2025_TT-BNNMT_672724.pdf\n",
      "    â”œâ”€â”€ thong_tu_59_2022_TT-BTC_531022.pdf\n",
      "    â”œâ”€â”€ thong_tu_59_2023_TT-BTC_577553.pdf\n",
      "    â”œâ”€â”€ thong_tu_59_2025_TT-BTC_662966.pdf\n",
      "    â”œâ”€â”€ thong_tu_64_2025_TT-BTC_662967.pdf\n",
      "    â”œâ”€â”€ thong_tu_71_2025_TT-BTC_663521.pdf\n",
      "    â”œâ”€â”€ thong_tu_73_2024_TT-BTC_621342.pdf\n",
      "    â”œâ”€â”€ thong_tu_74_2022_TT-BTC_547027.pdf\n",
      "    â”œâ”€â”€ thong_tu_75_2022_TT-BTC_547150.pdf\n",
      "    â”œâ”€â”€ thong_tu_80_2019_TT-BTC_429473.pdf\n",
      "    â”œâ”€â”€ thong_tu_82_2024_TT-BTC_633510.pdf\n",
      "    â””â”€â”€ thong_tu_86_2025_TT-BTC_671272.pdf\n"
     ]
    }
   ],
   "source": [
    "list_drive_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc13529",
   "metadata": {},
   "source": [
    "### Test Text (sample for 2 documents of different structure hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb3090e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "QUá»C Há»˜I  \n",
    "-------  Cá»˜NG HÃ’A XÃƒ Há»˜I CHá»¦ NGHÄ¨A VIá»†T NAM  \n",
    "Äá»™c láº­p - Tá»± do - Háº¡nh phÃºc  \n",
    "---------------  \n",
    "Luáº­t sá»‘: 23/2026/QH  HÃ  Ná»™i, ngÃ y 20 thÃ¡ng 1 nÄƒm 2026\n",
    "  \n",
    "LUáº¬T  \n",
    "THUáº¾ Thu nháº­p Máº«u\n",
    "CÄƒn cá»© Hiáº¿n phÃ¡p nÆ°á»›c Cá»™ng hÃ²a xÃ£ há»™i chá»§ nghÄ©a Viá»‡t Nam; \n",
    "CÄƒn cá»© Luáº­t thuáº¿ Thu Nháº­p Doanh Nghiá»‡p sá»‘ 67/2025/QH15;\n",
    "Quá»‘c há»™i ban hÃ nh Luáº­t Thuáº¿ thu nháº­p doanh nghiá»‡p.  \n",
    "\n",
    "Äiá»u 1. Pháº¡m vi Ä‘iá»u chá»‰nh  \n",
    "Luáº­t nÃ y quy Ä‘á»‹nh vá» ngÆ°á»i ná»™p thuáº¿, thu nháº­p chá»‹u thuáº¿, thu nháº­p Ä‘Æ°á»£c miá»…n thuáº¿, cÄƒn cá»© tÃ­nh \n",
    "thuáº¿, phÆ°Æ¡ng phÃ¡p tÃ­nh thuáº¿ vÃ  Æ°u Ä‘Ã£i thuáº¿ thu nháº­p doanh nghiá»‡p.  \n",
    "\n",
    "1.CÃ¡c quy Ä‘á»‹nh Ä‘Æ°á»£c liá»‡t kÃª táº¡i Äiá»u nÃ y Ä‘Æ°á»£c há»§y bá» vÃ  thay tháº¿ báº±ng cÃ¡c Ä‘iá»u má»›i.\n",
    "\n",
    "a) CÃ¡c quy Ä‘á»‹nh táº¡i khoáº£n 1 Äiá»u 1 Ä‘Æ°á»£c há»§y bá» vÃ  thay tháº¿ bÃªn dÆ°á»›i.\n",
    "\n",
    "a.1) CÃ¡c quy Ä‘á»‹nh táº¡i Äiá»ƒm a) khoáº£n 1 Ä‘iá»u nÃ y Ä‘Æ°á»£c bá»• sung.\n",
    "\n",
    "a.1.1) CÃ¡c quy Ä‘á»‹nh táº¡i Ä‘iá»ƒm a.1) khoáº£n 1 Äiá»u nÃ y Ä‘Æ°á»£c sá»­a Ä‘á»•i.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e26c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "QUá»C Há»˜I  \n",
    "-------  Cá»˜NG HÃ’A XÃƒ Há»˜I CHá»¦ NGHÄ¨A VIá»†T NAM  \n",
    "Äá»™c láº­p - Tá»± do - Háº¡nh phÃºc  \n",
    "---------------  \n",
    "Luáº­t sá»‘: 67/2025/QH15  HÃ  Ná»™i, ngÃ y 14 thÃ¡ng 6 nÄƒm 2025  \n",
    "  \n",
    "LUáº¬T  \n",
    "THUáº¾ THU NHáº¬P DOANH NGHIá»†P  \n",
    "CÄƒn cá»© Hiáº¿n phÃ¡p nÆ°á»›c Cá»™ng hÃ²a xÃ£ há»™i chá»§ nghÄ©a Viá»‡t Nam;  \n",
    "Quá»‘c há»™i ban hÃ nh Luáº­t Thuáº¿ thu nháº­p doanh nghiá»‡p.  \n",
    "\n",
    "ChÆ°Æ¡ng I  \n",
    "\n",
    "NHá»®NG QUY Äá»ŠNH CHUNG. \n",
    "\n",
    "Sá»­a Ä‘á»•i bá»• sung Ä‘iá»ƒm a Ä‘áº¿n Ä‘iá»ƒm e Ä‘iá»u 32 hoáº·c Ä‘iá»u 35, Ä‘iá»ƒm b.1.1), \n",
    "Ä‘iá»ƒm c.1), Ä‘iá»ƒm d.1) hoáº·c Ä‘iá»ƒm e.2) khoáº£n 2 Ä‘iá»u 1, khoáº£n 3 Ä‘iá»u 10 luáº­t sá»‘ 20/2019/QH14.\n",
    "\n",
    "Há»§y bá» Luáº­t nÃ y vÃ  cÃ¡c Ä‘iá»u liÃªn quan Ä‘áº¿n nÃ³.\n",
    "\n",
    "Äiá»u 1. Pháº¡m vi Ä‘iá»u chá»‰nh  \n",
    "Luáº­t nÃ y quy Ä‘á»‹nh vá» ngÆ°á»i ná»™p thuáº¿, thu nháº­p chá»‹u thuáº¿, thu nháº­p Ä‘Æ°á»£c miá»…n thuáº¿, cÄƒn cá»© tÃ­nh \n",
    "thuáº¿, phÆ°Æ¡ng phÃ¡p tÃ­nh thuáº¿ vÃ  Æ°u Ä‘Ã£i thuáº¿ thu nháº­p doanh nghiá»‡p.  \n",
    "\n",
    "Sá»­a Ä‘á»•i bá»‘ sung ChÆ°Æ¡ng nÃ y vÃ  cÃ¡c Ä‘iá»u liÃªn quan.\n",
    "\n",
    "1.CÃ¡c quy Ä‘á»‹nh Ä‘Æ°á»£c liá»‡t kÃª táº¡i Äiá»u nÃ y Ä‘Æ°á»£c há»§y bá» vÃ  thay tháº¿ báº±ng cÃ¡c Ä‘iá»u má»›i.\n",
    "\n",
    "a) CÃ¡c quy Ä‘á»‹nh táº¡i khoáº£n 1 Äiá»u 1 chÆ°Æ¡ng nÃ y Ä‘Æ°á»£c há»§y bá» vÃ  thay tháº¿ bÃªn dÆ°á»›i.\n",
    "\n",
    "a.1) CÃ¡c quy Ä‘á»‹nh táº¡i Äiá»ƒm a) khoáº£n 1 Ä‘iá»u nÃ y Ä‘Æ°á»£c bá»• sung.\n",
    "\n",
    "a.1.1) CÃ¡c quy Ä‘á»‹nh táº¡i Ä‘iá»ƒm a.1) khoáº£n 1 Äiá»u 1 chÆ°Æ¡ng nÃ y Ä‘Æ°á»£c sá»­a Ä‘á»•i.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "032311c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = read_drive_file('luat_22_2023_QH15_518805.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43c49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.saving_neo4j_for_retrieve(doc, 'Test_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c27150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1320 chunk nodes to embed\n"
     ]
    }
   ],
   "source": [
    "processor.very_cool_chunking_with_graph('Test_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a6d2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "path = 'D:/Study/Education/Projects/Group_Project/source/document/original_doc'\n",
    "list_folder = ['luat', 'nghi_dinh', 'nghi_quyet', 'quyet_dinh', 'thong_tu']\n",
    "\n",
    "records = []\n",
    "\n",
    "for folder in list_folder:\n",
    "    folder_path = f\"{path}/{folder}\"\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    for file in files:\n",
    "        pdf_path = f\"{folder_path}/{file}\"\n",
    "        try:\n",
    "            reader = PdfReader(pdf_path)\n",
    "            num_pages = len(reader.pages)\n",
    "        except Exception as e:\n",
    "            num_pages = None\n",
    "            print(f\"Error reading {pdf_path}: {e}\")\n",
    "\n",
    "        records.append({\n",
    "            'filename': file,\n",
    "            'pages': num_pages\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5a5217a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = 'D:/Study/Education/Projects/Group_Project/source/document/original_doc'\n",
    "list_folder = ['luat', 'nghi_dinh', 'nghi_quyet', 'quyet_dinh', 'thong_tu']\n",
    "\n",
    "folder_counts = {}\n",
    "\n",
    "for folder in list_folder:\n",
    "    folder_path = f\"{path}/{folder}\"\n",
    "    files = os.listdir(folder_path)\n",
    "    folder_counts[folder] = len(files)\n",
    "\n",
    "rename_map = {\n",
    "    'luat': 'Law',\n",
    "    'nghi_quyet': 'Resolution',\n",
    "    'nghi_dinh': 'Decree',\n",
    "    'thong_tu': 'Circular',\n",
    "    'quyet_dinh': 'Decision'\n",
    "}\n",
    "\n",
    "# Apply renaming\n",
    "folders_en = [rename_map[f] for f in folder_counts.keys()]\n",
    "counts = list(folder_counts.values())\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(folders_en, counts)\n",
    "plt.xlabel(\"Document Type\")\n",
    "plt.ylabel(\"Number of Files\")\n",
    "plt.title(\"Number of PDF Files in Each Category\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a53b32ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'luat': 11,\n",
       " 'nghi_dinh': 46,\n",
       " 'nghi_quyet': 31,\n",
       " 'quyet_dinh': 25,\n",
       " 'thong_tu': 52}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2e629ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11+46+31+25+52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5fdb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New tab created and DataFrame written to Google Sheet: file_info'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_df_to_gs(df, 'file_info')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phobert_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
